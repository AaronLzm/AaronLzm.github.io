---
title: Chapter_11
category: Causal inference
tags: [DeepSeek-R1-0528,response_md]

---
<think>
We are summarizing Chapter 11 of the book "Causal Inference: What If" by Hernán and Robins. The chapter is titled "Why Model?" and is divided into several sections. We will summarize each section step by step, extracting technical points and fine points as required.

The chapter begins by contrasting Part I (conceptual, minimal calculations) and Part II (requiring regression models and computers) of the book. The chapter's goal is to explain the differences between nonparametric and parametric estimators, introduce smoothing and the bias-variance trade-off, and motivate the need for models in data analysis.

We note that the chapter includes several figures (11.1 to 11.5) which we cannot see, but we can describe based on the text.

We break down the chapter by sections:

11.1 Data cannot speak for themselves
11.2 Parametric estimators of the conditional mean
11.3 Nonparametric estimators of the conditional mean
11.4 Smoothing
11.5 The bias-variance trade-off

Additionally, there are two Fine Points (11.1 and 11.2) and one Technical Point (11.1) that we will summarize in their respective sections.

Let's proceed section by section.

### 11.1 Data cannot speak for themselves
This section uses an example with 16 HIV-infected individuals to illustrate that when the treatment variable has many levels (or is continuous), we cannot always compute sample averages for every treatment level because some levels may have no individuals. This necessitates the use of models.

### 11.2 Parametric estimators of the conditional mean
This section introduces parametric models to estimate conditional means when data are sparse. The example uses a linear model to estimate E[Y|A=90] even though no individual received A=90.

### 11.3 Nonparametric estimators of the conditional mean
This section defines nonparametric estimators and saturated models. It explains that nonparametric estimators (like the sample average) do not impose restrictions but are only possible when there is data for every level of the variable.

### 11.4 Smoothing
This section discusses how models with different numbers of parameters lead to different degrees of smoothing. More parameters lead to less smoothing (more wiggly curves), fewer parameters lead to more smoothing.

### 11.5 The bias-variance trade-off
This section explains that models with more parameters are less likely to be misspecified (less bias) but result in higher variance (wider confidence intervals). This trade-off is central to model selection.

We will now write the summary in the required format.
</think>
### Chapter 11: WHY MODEL?

#### 11.1 Data cannot speak for themselves  
**技术重点（Technical Points）**:  
- **核心理论**: 当处理变量 \(A\) 是连续或多分类时，特定处理水平（如 \(A=90\)）可能无观测数据，导致非参数估计器（如样本均值）无法计算。  
- **重要概念**:  
  - **估计量（Estimator）**: 用于估计总体参数的函数（如样本均值）。  
  - **一致性估计量（Consistent Estimator）**: 样本量增大时，估计值收敛于总体参数（如样本均值一致，首个观测值非一致）。  
- **应用场景**: 处理变量为离散（二分类/多分类）或连续时，估计条件期望 \(E[Y|A=a]\)。  

**细节要点（Fine Points）**:  
- **案例分析**: 16名HIV感染者研究：  
  - 二分类处理（\(A=0/1\)）: 样本均值估计 \(E[Y|A=1]=146.25\), \(E[Y|A=0]=67.50\)。  
  - 四分类处理（\(A=1,2,3,4\)）: 样本均值估计分别为 \(70.0, 80.0, 117.5, 195.0\)，置信区间更宽（样本稀疏）。  
  - 连续处理（\(A=0-100\)）: 无 \(A=90\) 的个体，样本均值未定义。  
- **辅助信息**: 连续变量可视为无限分类，需模型补充数据不足。  

---

#### 11.2 Parametric estimators of the conditional mean  
**技术重点（Technical Points）**:  
- **核心理论**: 参数模型通过先验限制（如线性函数形式）估计条件期望。  
- **关键公式**: 线性均值模型：  
  $$E[Y|A] = \theta_0 + \theta_1 A$$  
- **重要概念**:  
  - **参数模型（Parametric Model）**: 用有限参数描述条件期望（如 \(\theta_0, \theta_1\) 定义直线）。  
  - **普通最小二乘法（OLS）**: 最小化残差平方和估计参数：  
    $$\min_{\theta_0, \theta_1} \sum_{i=1}^n (Y_i - (\theta_0 + \theta_1 A_i))^2$$  
- **应用场景**: 估计无观测的处理水平（如 \(A=90\)) 的条件期望。  

**细节要点（Fine Points）**:  
- **案例分析**: 基于图11.3数据：  
  - OLS估计 \(\hat{\theta}_0 = 24.55\), \(\hat{\theta}_1 = 2.14\) → \(E[Y|A=90] = 24.55 + 90 \times 2.14 = 216.9\)。  
  - 95%置信区间: \((172.1, 261.6)\)（同方差假设下）。  
- **相关背景**: 模型通过借用其他 \(A\) 值的信息进行平滑，但需模型正确设定（no model misspecification）。  

---

#### 11.3 Nonparametric estimators of the conditional mean  
**技术重点（Technical Points）**:  
- **核心理论**: 非参数估计器无先验限制，直接基于数据估计（如样本均值）。  
- **重要概念**:  
  - **饱和模型（Saturated Model）**: 参数数量等于未知条件期望数（如二分类 \(A\) 时 \(E[Y|A] = \theta_0 + \theta_1 A\) 无限制）。  
  - **Fisher一致性估计器**: 当样本=总体时，估计值等于真实参数（非参数MLE）。  
- **应用场景**: 离散处理变量且每个水平有数据时（如Part I的标准化、IP加权）。  

**细节要点（Fine Points）**:  
- **案例分析**:  
  - 二分类 \(A\): 饱和模型估计与样本均值相同（\(\hat{E}[Y|A=0]=67.5\), \(\hat{E}[Y|A=1]=146.25\)）。  
  - 100水平 \(A\) 无 \(A=90\) 数据: 无非参数估计器。  
- **辅助信息**: Part I方法（无模型）基于饱和模型；Part II需参数模型补充数据不足。  

---

#### 11.4 Smoothing  
**技术重点（Technical Points）**:  
- **核心理论**: 参数数量决定平滑度：参数少→高平滑（直线），参数多→低平滑（过拟合）。  
- **关键公式**: 多项式扩展模型（如二次项）：  
  $$E[Y|A] = \theta_0 + \theta_1 A + \theta_2 A^2$$  
- **重要概念**:  
  - **线性模型定义**: 参数线性组合（如 \(A^2\) 是非线性变量，但模型线性于 \theta\)。  
  - **平滑机制**: 借用邻近 \(A\) 值的信息（如窗口限制 \(A \in [80,100]\)）。  

**细节要点（Fine Points）**:  
- **案例分析**: 图11.3数据：  
  - 二次模型: \(\hat{\theta}_0 = -7.41\), \(\hat{\theta}_1 = 4.11\), \(\hat{\theta}_2 = -0.02\) → \(E[Y|A=90] = 197.1\)。  
  - 95%置信区间: \((142.8, 251.5)\)（比线性模型更宽）。  
- **辅助信息**: 高维协变量时，平滑概念不变（参数少→响应曲面更平滑）。  

---

#### 11.5 The bias-variance trade-off  
**技术重点（Technical Points）**:  
- **核心理论**: 偏差-方差权衡：  
  - 参数多→限制少→偏差↓但方差↑（置信区间宽）。  
  - 参数少→限制多→偏差↑但方差↓。  
- **重要概念**:  
  - **模型误设（Misspecification）**: 模型限制错误导致估计偏差。  
  - **校正不足（Miscalibration）**: 偏差存在时，置信区间覆盖真实参数概率低于95%。  

**细节要点（Fine Points）**:  
- **案例分析**: 图11.3数据：  
  - 线性模型: \(\hat{E}[Y|A=90] = 216.9\) (CI: \(172.1, 261.6\))。  
  - 二次模型: \(\hat{E}[Y|A=90] = 197.1\) (CI: \(142.8, 251.5\))。  
- **相关背景**: 实际中选择模型需权衡传统、可解释性、软件可用性；建议敏感性分析检验模型稳健性。  

---

### 逻辑关联性  
本章从数据局限性（11.1）引出参数模型（11.2）与非参数估计（11.3），进而讨论平滑（11.4）和偏差-方差权衡（11.5），逐步构建模型必要性框架。全章为Part II的因果推断模型奠定基础，强调模型在数据稀疏时的不可替代性及误设风险。  

> **注**: 图中信息（Fig 11.1-11.5）基于文本描述总结；未明确细节标注为"需进一步查证"。公式严格使用LaTeX格式，术语保留英文确保准确性。