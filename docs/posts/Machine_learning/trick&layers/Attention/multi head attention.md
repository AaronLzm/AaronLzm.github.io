---
title: multi head attention
category: Machine Learning
tags: [Machine Learning,Attention]

---
### å¤šå¤´æ³¨æ„åŠ›ï¼ˆMulti-Head Attentionï¼‰æ•°å­¦è¯¦è§£

å¤šå¤´æ³¨æ„åŠ›æ˜¯ Transformer çš„æ ¸å¿ƒæœºåˆ¶ï¼Œå®ƒé€šè¿‡å¹¶è¡Œæ‰§è¡Œå¤šä¸ªç‹¬ç«‹çš„æ³¨æ„åŠ›å¤´ï¼ˆattention headsï¼‰æ¥æ•æ‰è¾“å…¥çš„ä¸åŒè¡¨ç¤ºå­ç©ºé—´ã€‚ä»¥ä¸‹æ˜¯å®Œæ•´çš„æ•°å­¦æ¨å¯¼ï¼ˆæ‰€æœ‰å…¬å¼ç”¨ `$` åŒ…è£¹ï¼‰ï¼š

---

#### **1. è¾“å…¥è¡¨ç¤º**
è¾“å…¥åºåˆ—çŸ©é˜µï¼š
$$
X \in \mathbb{R}^{n \times d_{\text{model}}}
$$
å…¶ä¸­ï¼š
- $n$ï¼šåºåˆ—é•¿åº¦
- $d_{\text{model}}$ï¼šæ¨¡å‹ç»´åº¦ï¼ˆå¦‚ 512ï¼‰

---

#### **2. å¤šå¤´æŠ•å½±**
å¯¹æ¯ä¸ªå¤´ $i \in \{1, 2, \dots, h\}$ï¼Œä½¿ç”¨ç‹¬ç«‹çš„æƒé‡çŸ©é˜µè¿›è¡ŒæŠ•å½±ï¼š
$$
\begin{align*}
Q_i &= X \cdot W_i^Q, \quad &W_i^Q \in \mathbb{R}^{d_{\text{model}} \times d_k} \\
K_i &= X \cdot W_i^K, \quad &W_i^K \in \mathbb{R}^{d_{\text{model}} \times d_k} \\
V_i &= X \cdot W_i^V, \quad &W_i^V \in \mathbb{R}^{d_{\text{model}} \times d_v}
\end{align*}
$$
å‚æ•°è¯´æ˜ï¼š
- $h$ï¼šå¤´æ•°ï¼ˆå¦‚ 8ï¼‰
- $d_k = d_v = \frac{d_{\text{model}}}{h}$ï¼šæ¯ä¸ªå¤´çš„ç»´åº¦ï¼ˆå¦‚ 64ï¼‰
- æŠ•å½±åç»´åº¦ï¼š$Q_i, K_i \in \mathbb{R}^{n \times d_k}$ï¼Œ$V_i \in \mathbb{R}^{n \times d_v}$

---

#### **3. å•å¤´æ³¨æ„åŠ›è®¡ç®—**
å¯¹æ¯ä¸ªå¤´ $i$ ç‹¬ç«‹è®¡ç®—ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›ï¼š
$$
\text{head}_i = \text{Attention}(Q_i, K_i, V_i) = \text{softmax}\left( \frac{Q_i K_i^T}{\sqrt{d_k}} \right) V_i
$$
å…¶ä¸­ï¼š
- $\frac{Q_i K_i^T}{\sqrt{d_k}} \in \mathbb{R}^{n \times n}$ï¼šç¼©æ”¾åçš„æ³¨æ„åŠ›åˆ†æ•°çŸ©é˜µ
- è¾“å‡ºç»´åº¦ï¼š$\text{head}_i \in \mathbb{R}^{n \times d_v}$

---

#### **4. å¤šå¤´è¾“å‡ºæ‹¼æ¥**
å°†æ‰€æœ‰å¤´çš„è¾“å‡ºåœ¨ç‰¹å¾ç»´åº¦æ‹¼æ¥ï¼š
$$
\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, \text{head}_2, \dots, \text{head}_h)
$$
æ‹¼æ¥åç»´åº¦ï¼š$\text{Concat}(\cdots) \in \mathbb{R}^{n \times (h \cdot d_v)} = \mathbb{R}^{n \times d_{\text{model}}}$

---

#### **5. è¾“å‡ºçº¿æ€§å˜æ¢**
å°†æ‹¼æ¥ç»“æœé€šè¿‡å¯å­¦ä¹ æƒé‡çŸ©é˜µ $W^O$ æŠ•å½±å›æ¨¡å‹ç»´åº¦ï¼š
$$
\text{Output} = \text{Concat}(\text{head}_1, \dots, \text{head}_h) \cdot W^O, \quad W^O \in \mathbb{R}^{d_{\text{model}} \times d_{\text{model}}}
$$
æœ€ç»ˆè¾“å‡ºç»´åº¦ï¼š$\mathbb{R}^{n \times d_{\text{model}}}$

---

### **å®Œæ•´æ•°å­¦å…¬å¼æ±‡æ€»**
$$
\boxed{
\begin{align*}
& \text{MultiHead}(X) = \text{Concat}(\text{head}_1, \dots, \text{head}_h) \cdot W^O \\
& \text{where} \quad \text{head}_i = \text{softmax}\left( \frac{(X W_i^Q)(X W_i^K)^T}{\sqrt{d_k}} \right) (X W_i^V) \\
& \text{with} \quad 
\begin{cases} 
d_k = d_v = \dfrac{d_{\text{model}}}{h} \\
W_i^Q, W_i^K \in \mathbb{R}^{d_{\text{model}} \times d_k} \\
W_i^V \in \mathbb{R}^{d_{\text{model}} \times d_v} \\
W^O \in \mathbb{R}^{d_{\text{model}} \times d_{\text{model}}}
\end{cases}
\end{align*}
}
$$

---

### **ç»´åº¦å˜åŒ–å¯è§†åŒ–**
```
è¾“å…¥ X: [n, d_model]
â”‚
â”œâ”€ Head 1 â”€â”€â”
â”‚ Q1 = XÂ·W1^Q [n, d_k]  â”‚
â”‚ K1 = XÂ·W1^K [n, d_k]  â†’ Attn1 [n, n] â†’ head1 [n, d_v]
â”‚ V1 = XÂ·W1^V [n, d_v]  â”‚               â”‚
â”œâ”€ Head 2 â”€â”€â”¤                              â”‚
â”‚ ...      â”‚                              â”œâ†’ Concat [n, hÂ·d_v] = [n, d_model]
â”œâ”€ Head h â”€â”€â”¤                              â”‚
â”‚          â”‚                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
                                          â”‚
Output = ConcatÂ·W^O [n, d_model] â†â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```mermaid
graph LR
X[X: nÃ—d_model] --> Q[åˆ†å¤´æŠ•å½±]
X --> K[åˆ†å¤´æŠ•å½±]
X --> V[åˆ†å¤´æŠ•å½±]
Q --> Q1[å¤´1 Q: nÃ—dk] & Q2[å¤´2 Q: nÃ—dk] & Qh[å¤´h Q: nÃ—dk]
K --> K1[å¤´1 K: nÃ—dk] & K2[å¤´2 K: nÃ—dk] & Kh[å¤´h K: nÃ—dk]
V --> V1[å¤´1 V: nÃ—dv] & V2[å¤´2 V: nÃ—dv] & Vh[å¤´h V: nÃ—dv]
Q1 & K1 & V1 --> Head1[å¤´1è¾“å‡º: nÃ—dv]
Q2 & K2 & V2 --> Head2[å¤´2è¾“å‡º: nÃ—dv]
Qh & Kh & Vh --> Headh[å¤´hè¾“å‡º: nÃ—dv]
Head1 & Head2 & Headh --> Concat[æ‹¼æ¥: nÃ—d_model]
Concat --> WO[W^O: d_modelÃ—d_model]
WO --> Output[è¾“å‡º: nÃ—d_model]
```


---

### **æ•°å­¦ä¼˜åŠ¿åˆ†æ**
1. **å­ç©ºé—´åˆ†è§£**  
   æ¯ä¸ªå¤´å­¦ä¹ ä¸åŒçš„æŠ•å½±ï¼š
   $$
   W_i^Q, W_i^K, W_i^V \text{ ç›¸äº’ç‹¬ç«‹}
   $$
   ä½¿æ¨¡å‹å…³æ³¨ä¸åŒæ–¹é¢çš„ä¿¡æ¯ï¼ˆå¦‚è¯­æ³•/è¯­ä¹‰/ä½ç½®ï¼‰ã€‚

2. **è®¡ç®—æ•ˆç‡**  
   è™½ç„¶å¤´æ•° $h$ å¢åŠ ï¼Œä½†å•å¤´ç»´åº¦ $d_k$ å‡å°ï¼š
   $$
   \text{å•å¤´è®¡ç®—é‡} = O(n^2 d_k) = O\left(n^2 \frac{d_{\text{model}}}{h}\right)
   $$
   æ€»è®¡ç®—é‡ $O(n^2 d_{\text{model}})$ ä¸å•å¤´ç›¸åŒã€‚

3. **è¡¨è¾¾èƒ½åŠ›å¢å¼º**  
   è¾“å‡ºæ˜¯å¤šä¸ªå­ç©ºé—´çš„éçº¿æ€§ç»„åˆï¼š
   $$
   \text{Output} = f\left( \sum_{i=1}^h \text{head}_i \cdot W^O_i \right)
   $$
   ï¼ˆ$W^O$ éšå«åˆ†è§£ä¸ºå­çŸ©é˜µ $W^O_i$ï¼‰

---

### **å®ä¾‹æ¼”ç®—**
è®¾ $d_{\text{model}} = 4$, $h = 2$, åˆ™ $d_k = d_v = 2$  
è¾“å…¥ $X = \begin{bmatrix} 1 & 0.5 & -1 & 2 \\ -0.5 & 1 & 0.3 & -2 \end{bmatrix}$

**å¤´1è®¡ç®—**ï¼š
$$
W_1^Q = \begin{bmatrix} 0.1 & 0.4 \\ -0.2 & 0.3 \\ 1.0 & -0.5 \\ 0.5 & 0.2 \end{bmatrix}, \ 
Q_1 = X W_1^Q = \begin{bmatrix} 0.85 & -0.05 \\ -0.29 & 0.74 \end{bmatrix}
$$
ï¼ˆç±»ä¼¼è®¡ç®— $K_1$, $V_1$ åæ±‚ $\text{head}_1$ï¼‰

**å¤´2è®¡ç®—**ï¼š
$$
W_2^Q = \begin{bmatrix} -0.3 & 0.2 \\ 1.1 & 0.6 \\ -0.4 & 0.8 \\ 0.7 & -0.1 \end{bmatrix}, \ 
Q_2 = X W_2^Q = \begin{bmatrix} 2.15 & 0.65 \\ -1.32 & 1.02 \end{bmatrix}
$$

**æ‹¼æ¥ä¸è¾“å‡º**ï¼š
$$
\text{Concat} = \begin{bmatrix} \text{head}_1^{(1)} & \text{head}_1^{(2)} & \text{head}_2^{(1)} & \text{head}_2^{(2)} \end{bmatrix}
$$
$$
W^O = \begin{bmatrix} 0.5 & -0.2 & 1.1 & 0.3 \\ 0.1 & 0.8 & -0.4 & 0.6 \\ -0.3 & 0.7 & 0.2 & 1.0 \\ 0.9 & -0.5 & 0.3 & -0.8 \end{bmatrix}, \ 
\text{Output} = \text{Concat} \cdot W^O
$$

---

### **ä¸ä¼ ç»Ÿå•å¤´å¯¹æ¯”**
| ç‰¹æ€§         | å•å¤´æ³¨æ„åŠ›               | å¤šå¤´æ³¨æ„åŠ›                     |
|--------------|--------------------------|--------------------------------|
| **å‚æ•°é‡**   | $3d_{\text{model}}^2$    | $3d_{\text{model}}^2$ (ç›¸åŒ)   |
| **è®¡ç®—å¤æ‚åº¦** | $O(n^2 d_{\text{model}})$ | $O(n^2 d_{\text{model}})$      |
| **è¡¨è¾¾èƒ½åŠ›** | å•ä¸€è¡¨ç¤ºç©ºé—´             | $h$ ä¸ªæ­£äº¤å­ç©ºé—´               |
| **å¹¶è¡Œæ€§**   | ä½                       | é«˜ï¼ˆå¤´é—´å®Œå…¨å¹¶è¡Œï¼‰             |

---

### **ä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿ**
1. **å¤šæ ·æ€§**ï¼šä¸åŒå¤´å…³æ³¨ä¸åŒæ¨¡å¼ï¼ˆå¦‚å±€éƒ¨ä¾èµ– vs å…¨å±€ä¾èµ–ï¼‰
   $$
   \text{head}_i \text{ å­¦ä¹ ç‹¬ç«‹çš„å…³ç³»è¡¨ç¤º}
   $$
2. **ç»´åº¦åˆ†è§£**ï¼šå°†é«˜ç»´ç©ºé—´åˆ†è§£ä¸ºä½ç»´å­ç©ºé—´ï¼Œé™ä½å­¦ä¹ éš¾åº¦
   $$
   \mathbb{R}^{d_{\text{model}}} \to \oplus_{i=1}^h \mathbb{R}^{d_k}
   $$
3. **æ®‹å·®è¿æ¥**ï¼šå¤šå¤´è¾“å‡ºé€šè¿‡æ®‹å·®è¿æ¥ä¼ é€’åˆ°å‰é¦ˆç½‘ç»œï¼Œä¿ç•™åŸå§‹ä¿¡æ¯ï¼š
   $$
   \text{LayerOutput} = \text{LayerNorm}(X + \text{MultiHead}(X))
   $$

å¤šå¤´æ³¨æ„åŠ›é€šè¿‡è¿™ç§"åˆ†æ²»ç­–ç•¥"ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹æ•æ‰å¤æ‚ä¾èµ–å…³ç³»çš„èƒ½åŠ›ï¼Œæˆä¸º Transformer æ¶æ„çš„æ ¸å¿ƒåˆ›æ–°ã€‚º Transformer æ¶æ„çš„æ ¸å¿ƒåˆ›æ–°ã€‚