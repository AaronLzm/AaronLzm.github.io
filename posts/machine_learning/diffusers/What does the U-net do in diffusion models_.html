<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.23" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.93" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"What does the U-net do in diffusion models?","image":[""],"dateModified":"2025-09-11T11:24:19.000Z","author":[{"@type":"Person","name":"Aaron L","url":"https://aaronlzm.github.io","email":"lzm_aaron@outlook.com"}]}</script><meta property="og:url" content="https://aaronlzm.github.io/posts/machine_learning/diffusers/What%20does%20the%20U-net%20do%20in%20diffusion%20models_.html"><meta property="og:site_name" content="Aaron's Blog"><meta property="og:title" content="What does the U-net do in diffusion models?"><meta property="og:description" content="At its core, the U-Net in a diffusion model acts as the engine of the reverse diffusion process. In simple terms, diffusion models work by first progressively adding noise to an..."><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:updated_time" content="2025-09-11T11:24:19.000Z"><meta property="article:modified_time" content="2025-09-11T11:24:19.000Z"><title>What does the U-net do in diffusion models? | Aaron's Blog</title><meta name="description" content="At its core, the U-Net in a diffusion model acts as the engine of the reverse diffusion process. In simple terms, diffusion models work by first progressively adding noise to an...">
    <link rel="preload" href="/assets/style-lRDsT6sh.css" as="style"><link rel="stylesheet" href="/assets/style-lRDsT6sh.css">
    <link rel="modulepreload" href="/assets/app-DOCQVc6u.js"><link rel="modulepreload" href="/assets/What does the U-net do in diffusion models_.html-CvVMGHhE.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-1jsJjItB.js" as="script"><link rel="prefetch" href="/assets/intro.html-DECbY87S.js" as="script"><link rel="prefetch" href="/assets/index.html-DX2asHH7.js" as="script"><link rel="prefetch" href="/assets/disable.html-D42mO7cX.js" as="script"><link rel="prefetch" href="/assets/encrypt.html-MHA_fo3Z.js" as="script"><link rel="prefetch" href="/assets/layout.html-CCp4XBU1.js" as="script"><link rel="prefetch" href="/assets/markdown.html-kt1cu_YT.js" as="script"><link rel="prefetch" href="/assets/page.html-DoVrJjUc.js" as="script"><link rel="prefetch" href="/assets/index.html-A4bTICK6.js" as="script"><link rel="prefetch" href="/assets/intro.html-BMcP4kHH.js" as="script"><link rel="prefetch" href="/assets/Resources.html-D8sjNSgG.js" as="script"><link rel="prefetch" href="/assets/notice.html-DXfEN8wI.js" as="script"><link rel="prefetch" href="/assets/All bayesian inference methods.html-zzUb99uX.js" as="script"><link rel="prefetch" href="/assets/Bayes by backprop - naive variational inference.html-AczbNlx2.js" as="script"><link rel="prefetch" href="/assets/Difference between MCMC and VI(SVI).html-Bii_v5eO.js" as="script"><link rel="prefetch" href="/assets/Laplace Approximation.html-BWnuLppa.js" as="script"><link rel="prefetch" href="/assets/Markov Chain Monte Carlo(MCMC).html-2CTyvLM3.js" as="script"><link rel="prefetch" href="/assets/Prior Uncertainty - A Key Hurdle in Advancing Bayesian Machine Learning.html-DP2AU2AE.js" as="script"><link rel="prefetch" href="/assets/Stochastic Variational Inference.html-DCsl_0Eu.js" as="script"><link rel="prefetch" href="/assets/What is uncertainty in neural networks.html-CFa2URvN.js" as="script"><link rel="prefetch" href="/assets/Why we are assuming all weight distributions are Gaussian.html-My74ugGQ.js" as="script"><link rel="prefetch" href="/assets/reparameter trick.html-iodw5-b4.js" as="script"><link rel="prefetch" href="/assets/ViT.html-Bk1mPBL7.js" as="script"><link rel="prefetch" href="/assets/How to build EBMs.html-CSPjcSIs.js" as="script"><link rel="prefetch" href="/assets/How does diffusion model work.html-VvEJjaA7.js" as="script"><link rel="prefetch" href="/assets/KL Divergence in Variational Inference..html-BvcroyaF.js" as="script"><link rel="prefetch" href="/assets/KL and JS divergence.html-ByNv3POP.js" as="script"><link rel="prefetch" href="/assets/Norm 范数.html-_-MCGA0Y.js" as="script"><link rel="prefetch" href="/assets/Regularization for Deep Learning.html-BnIeUAhb.js" as="script"><link rel="prefetch" href="/assets/SVD.html-BIWxHzG7.js" as="script"><link rel="prefetch" href="/assets/Bayesian LSTM.html-BFfPPMA6.js" as="script"><link rel="prefetch" href="/assets/Global sparse momentum SGD.html-8HijybF9.js" as="script"><link rel="prefetch" href="/assets/How to write  literature review.html-De5baJYn.js" as="script"><link rel="prefetch" href="/assets/RL的主要结构种类.html-C5iLphxl.js" as="script"><link rel="prefetch" href="/assets/Generally_ DETR.html-CAV1AY9k.js" as="script"><link rel="prefetch" href="/assets/I-JEPA and ViT.html-CmSmpq_-.js" as="script"><link rel="prefetch" href="/assets/Mode Collapse_.html-BkEMOvRg.js" as="script"><link rel="prefetch" href="/assets/How PPO improved on mode collapsing.html-VN5WHYnb.js" as="script"><link rel="prefetch" href="/assets/mamba算法.html-DJfpBqTc.js" as="script"><link rel="prefetch" href="/assets/multi head attention.html-BynfL5c3.js" as="script"><link rel="prefetch" href="/assets/self-attention 自注意力.html-fKN6hdai.js" as="script"><link rel="prefetch" href="/assets/self-attention详细计算方法.html-Cim18j0f.js" as="script"><link rel="prefetch" href="/assets/单头 single head attention.html-Dw-xFCwv.js" as="script"><link rel="prefetch" href="/assets/单头attention back propagation.html-8CjCvym2.js" as="script"><link rel="prefetch" href="/assets/Transformer it self.html-C3XVZ7Aw.js" as="script"><link rel="prefetch" href="/assets/RMSNorm为什么有效.html-I0VQVapF.js" as="script"><link rel="prefetch" href="/assets/Rotary Position Embedding.html-CNOFIjCb.js" as="script"><link rel="prefetch" href="/assets/layer normalization - batch normalization.html-CLQT4F-Z.js" as="script"><link rel="prefetch" href="/assets/旋转位置编码RoPE详解.html-_KiDlEoD.js" as="script"><link rel="prefetch" href="/assets/知识蒸馏Knowledge Distillation.html-LjwIg-eX.js" as="script"><link rel="prefetch" href="/assets/404.html-BfEo0j-r.js" as="script"><link rel="prefetch" href="/assets/index.html-qokbwGlg.js" as="script"><link rel="prefetch" href="/assets/index.html-BK8h7SUG.js" as="script"><link rel="prefetch" href="/assets/index.html-Bw8y_cCL.js" as="script"><link rel="prefetch" href="/assets/index.html-gRp_HPah.js" as="script"><link rel="prefetch" href="/assets/index.html-Cg2LbMYR.js" as="script"><link rel="prefetch" href="/assets/index.html-b-m9kKTj.js" as="script"><link rel="prefetch" href="/assets/index.html-IGIeB8FL.js" as="script"><link rel="prefetch" href="/assets/index.html-Bt0qAt8a.js" as="script"><link rel="prefetch" href="/assets/index.html-A4AynFeF.js" as="script"><link rel="prefetch" href="/assets/index.html-D6zfBBK7.js" as="script"><link rel="prefetch" href="/assets/index.html-fptXpgkx.js" as="script"><link rel="prefetch" href="/assets/index.html-CwHxt4HK.js" as="script"><link rel="prefetch" href="/assets/index.html-D1jEHw3D.js" as="script"><link rel="prefetch" href="/assets/index.html-DUMlZUxd.js" as="script"><link rel="prefetch" href="/assets/index.html-Dc5gorAK.js" as="script"><link rel="prefetch" href="/assets/index.html-D6k9wEdm.js" as="script"><link rel="prefetch" href="/assets/index.html-Dn5JcMPM.js" as="script"><link rel="prefetch" href="/assets/index.html-DAl9iujm.js" as="script"><link rel="prefetch" href="/assets/index.html-DE2zfucE.js" as="script"><link rel="prefetch" href="/assets/index.html-COHThmXP.js" as="script"><link rel="prefetch" href="/assets/index.html-GeP-f6bP.js" as="script"><link rel="prefetch" href="/assets/index.html-BWC448Cq.js" as="script"><link rel="prefetch" href="/assets/index.html-B8-tVdmS.js" as="script"><link rel="prefetch" href="/assets/index.html-lGay1Pcc.js" as="script"><link rel="prefetch" href="/assets/index.html-DfS6qBiC.js" as="script"><link rel="prefetch" href="/assets/index.html-tZZU45Ty.js" as="script"><link rel="prefetch" href="/assets/index.html-MIQMzeLf.js" as="script"><link rel="prefetch" href="/assets/mermaid.esm.min-D5wLPOsR.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-D2Nf-uDI.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/" aria-label="Take me home"><img class="vp-nav-logo" src="https://avatars.githubusercontent.com/u/13514693?s=400&amp;u=c9045dcc8b2f95cdb2be77dbec13b54ce2ec8e43&amp;v=4" alt><!----><span class="vp-site-name hide-in-pad">Aaron&#39;s Blog</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="Blog Home"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:house" sizing="height" height="1em"></iconify-icon><!--]-->Blog Home<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/demo/" aria-label="Features demo"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:laptop-code" sizing="height" height="1em"></iconify-icon><!--]-->Features demo<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Posts"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:pen-to-square" sizing="height" height="1em"></iconify-icon>Posts<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">machine learning</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/machine_learning/CV/" aria-label="CV"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:pen-to-square" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->CV<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/machine_learning/Bayesian/" aria-label="Bayesian"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:pen-to-square" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->Bayesian<!----></a></li></ul></li></ul></button></div></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><div class="vp-nav-item"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Select language"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" name="i18n" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/posts/machine_learning/diffusers/What%20does%20the%20U-net%20do%20in%20diffusion%20models_.html" aria-label="English"><!---->English<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/zh/" aria-label="简体中文"><!---->简体中文<!----></a></li></ul></button></div></div><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/AaronLzm/AaronLzm.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="Blog Home"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:house" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->Blog Home<!----></a></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable"><iconify-icon class="vp-icon" icon="fa6-solid:laptop-code" sizing="both" width="1em" height="1em"></iconify-icon><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/demo/" aria-label="Demo"><!---->Demo<!----></a><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/demo/layout.html" aria-label="Layout"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:object-group" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->Layout<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/demo/markdown.html" aria-label="Markdown Enhance"><!--[--><iconify-icon class="vp-icon" icon="fa6-brands:markdown" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->Markdown Enhance<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/demo/page.html" aria-label="Page Config"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->Page Config<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/demo/disable.html" aria-label="Disabling layout and features"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:gears" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->Disabling layout and features<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/demo/encrypt.html" aria-label="Encryption Article"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:lock" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->Encryption Article<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><iconify-icon class="vp-icon" icon="fa6-solid:book" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">All articles</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Machine Learning</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Bayesian</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">CV</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Diffusers</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/posts/machine_learning/diffusers/How%20does%20diffusion%20model%20work.html" aria-label="How does diffusion model work"><!---->How does diffusion model work<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/posts/machine_learning/diffusers/What%20does%20the%20U-net%20do%20in%20diffusion%20models_.html" aria-label="What does the U-net do in diffusion models?"><!---->What does the U-net do in diffusion models?<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">EBM</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Mathematics</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Papers Read</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Reinforcement Learning</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/machine_learning/Resources.html" aria-label="Resources"><!---->Resources<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Trick&amp;layers</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li></ul></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/intro.html" aria-label="Zhimou(Aaron) Li"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:circle-info" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->Zhimou(Aaron) Li<!----></a></li><li><a class="auto-link external-link vp-sidebar-link" href="https://ecosystem.vuejs.press/plugins/markdown/revealjs/demo.html" aria-label="Slides" rel="noopener noreferrer" target="_blank"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:person-chalkboard" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->Slides<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->What does the U-net do in diffusion models?</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://aaronlzm.github.io" target="_blank" rel="noopener noreferrer">Aaron L</a></span><span property="author" content="Aaron L"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">9/11/25</span><meta property="datePublished" content="2025-09-11T08:03:52.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 3 min</span><meta property="timeRequired" content="PT3M"></span><!----><!----></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><p>At its core, the U-Net in a diffusion model acts as the engine of the reverse diffusion process. In simple terms, diffusion models work by first progressively adding noise to an image until it becomes pure noise (the forward process) and then learning to reverse this process to generate a new image from random noise (the reverse process). The U-Net is the neural network trained to perform this reversal, step by step.</p><p>The primary and most critical task of the U-Net is to <strong>predict the noise</strong> that was added to an image at a particular timestep. Given a noisy image at a specific step in the diffusion process, the U-Net analyzes it and outputs a prediction of the noise component. This predicted noise is then subtracted from the noisy image to produce a slightly less noisy version. This iterative denoising, guided by the U-Net, is what allows a diffusion model to generate a clean, coherent image from an initial field of random noise.</p><p>Now, let&#39;s delve into the finer technical points of why the U-Net is so well-suited for this task and how it operates within the diffusion model framework.</p><h3 id="key-technical-aspects-of-the-u-net-in-diffusion-models" tabindex="-1"><a class="header-anchor" href="#key-technical-aspects-of-the-u-net-in-diffusion-models"><span>Key Technical Aspects of the U-Net in Diffusion Models:</span></a></h3><ul><li><p><strong>Encoder-Decoder Structure:</strong> The U-Net is fundamentally an encoder-decoder network.</p><ul><li>The <strong>encoder</strong> part, also known as the contracting path, consists of a series of convolutional and downsampling layers (like max pooling). This path progressively reduces the spatial resolution of the input image while increasing the number of feature channels. The purpose is to capture the contextual, high-level features of the noisy image—what the image contains, but in a compressed representation.</li><li>The <strong>decoder</strong> part, or the expansive path, takes this compressed feature representation and progressively upsamples it, using transposed convolutions, to return to the original image resolution. Its job is to reconstruct the spatial details.</li></ul></li><li><p><strong>Skip Connections: The U-Net&#39;s &quot;Secret Sauce&quot;:</strong> This is arguably the most critical feature of the U-Net architecture for diffusion models.</p><ul><li>Skip connections directly link feature maps from the encoder to their corresponding layers in the decoder.</li><li>This is vital because the downsampling process in the encoder can lead to the loss of fine-grained spatial information. By feeding these high-resolution features from the encoder directly to the decoder, the network can combine the high-level context from the bottleneck with the precise, low-level details from earlier in the network.</li><li>For the task of noise prediction, these skip connections are essential for preserving the intricate details of the image, ensuring that the final generated output is sharp and not just a blurry approximation.</li></ul></li><li><p><strong>Input and Output Parity:</strong> A crucial requirement for the noise prediction network is that its output (the predicted noise) must have the same spatial dimensions as its input (the noisy image). The U-Net&#39;s symmetric encoder-decoder structure with skip connections is perfectly designed to handle this, making it a natural fit for the task.</p></li><li><p><strong>Timestep Conditioning:</strong> The amount of noise in an image is different at every step of the reverse diffusion process. The U-Net needs to know at which step it is operating to make an accurate prediction.</p><ul><li>This is achieved by providing the timestep <code>t</code> as an additional input to the U-Net.</li><li>Typically, the integer timestep is converted into a high-dimensional vector representation called a <strong>time embedding</strong>.</li><li>This time embedding is then usually added to the feature maps at various points within the U-Net&#39;s architecture, often in the residual blocks, allowing the network to modulate its behavior based on the current noise level.</li></ul></li><li><p><strong>Integration of Advanced Mechanisms:</strong> Modern U-Nets used in state-of-the-art diffusion models like Stable Diffusion incorporate several enhancements:</p><ul><li><strong>Residual Blocks:</strong> Instead of standard convolutional layers, many U-Nets use residual blocks. These blocks, which contain their own skip connections, help in training very deep networks by mitigating the vanishing gradient problem and improving the flow of information.</li><li><strong>Attention Mechanisms:</strong> Self-attention blocks are often integrated, particularly at lower resolutions in the U-Net. This allows the network to weigh the importance of different spatial locations in the image, enabling it to model long-range dependencies and understand the relationships between different parts of the image more effectively.</li><li><strong>Cross-Attention for Conditioning:</strong> In text-to-image models, the U-Net is further conditioned on the text prompt. This is often achieved by injecting the text embeddings into the U-Net using cross-attention layers. These layers allow the network to &quot;pay attention&quot; to relevant parts of the text prompt when generating different parts of the image.</li></ul></li></ul><p>In summary, the U-Net is not just an arbitrary choice of architecture; its inherent design is exceptionally well-suited for the iterative denoising process at the heart of diffusion models. Its ability to capture both high-level context and preserve fine-grained detail, all while being conditioned on the noise level (timestep), makes it the powerful and effective backbone for generating the high-quality images we see from modern diffusion models.</p></div><!----><!----><!----></div><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/AaronLzm/AaronLzm.github.io/edit/main/docs/posts/machine_learning/diffusers/What does the U-net do in diffusion models?.md" aria-label="Edit this page on GitHub" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page on GitHub<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">Last Updated</span><time class="vp-meta-info" datetime="2025-09-11T11:24:19.000Z" data-allow-mismatch>9/11/25, 11:24 AM</time></div><div class="contributors"><span class="vp-meta-label">Contributors: </span><!--[--><!--[--><span class="vp-meta-info" title="email: lizhimou@bytedance.com">lizhimou</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/posts/machine_learning/diffusers/How%20does%20diffusion%20model%20work.html" aria-label="How does diffusion model work"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><!---->How does diffusion model work</div></a><!----></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">Mind to drop me a mail?</div><div class="vp-copyright">Copyright © 2025 Aaron L </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/assets/app-DOCQVc6u.js" defer></script>
  </body>
</html>
