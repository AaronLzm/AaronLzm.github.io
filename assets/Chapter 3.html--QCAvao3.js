import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as i,f as n,b as a}from"./app-GBqwHtdL.js";const s={};function o(r,e){return a(),i("div",null,[...e[0]||(e[0]=[n('<h3 id="chapter-3-summary-observational-studies" tabindex="-1"><a class="header-anchor" href="#chapter-3-summary-observational-studies"><span>Chapter 3 Summary: Observational Studies</span></a></h3><p>This chapter focuses on causal inference from observational studies, contrasting them with randomized experiments. Key challenges include unmeasured confounding and the need for strong assumptions to estimate causal effects. The core framework involves emulating a <em>target trial</em> using observational data, relying on three <strong>identifiability conditions</strong>: exchangeability, positivity, and consistency. If these hold, methods like IP weighting or standardization can estimate causal effects. Below, I detail all main points, including conclusions from Technical Points (TP) and Fine Points (FP).</p><hr><h4 id="_1-observational-studies-vs-randomized-experiments" tabindex="-1"><a class="header-anchor" href="#_1-observational-studies-vs-randomized-experiments"><span><strong>1. Observational Studies vs. Randomized Experiments</strong></span></a></h4><ul><li><strong>Observational studies</strong>: Investigators observe and record data without intervening (e.g., studying if looking up causes others to look up). Criticisms include confounding (e.g., both pedestrians look up due to external factors like noise, not causation).</li><li><strong>Randomized experiments</strong>: Assign treatment randomly, ensuring exchangeability by design. Preferred for causal inference but often impractical (e.g., time-consuming, unethical, or unfeasible).</li><li><strong>Key limitation of observational studies</strong>: Associations may not imply causation due to unmeasured confounders. However, much scientific knowledge (e.g., evolution, global warming) derives from observational data.</li></ul><h4 id="_2-identifiability-conditions" tabindex="-1"><a class="header-anchor" href="#_2-identifiability-conditions"><span><strong>2. Identifiability Conditions</strong></span></a></h4><p>For causal effects to be identifiable from observational data, three conditions must hold (analogous to a conditionally randomized experiment):</p><ol><li><p><strong>Consistency</strong>: The treatment (a) must correspond to a <strong>well-defined</strong> intervention, and the observed outcome (Y) must equal the counterfactual outcome (Y^a) for individuals with (A = a):<br> [<br> Y = Y^a \\quad \\text{if} \\quad A = a<br> ]</p><ul><li>Requires precise specification of interventions (e.g., &quot;heart transplant&quot; includes surgical details). Vagueness (e.g., &quot;obesity&quot; without intervention method) undermines counterfactual definition.</li><li><strong>Conclusion from FP 3.3</strong>: States like obesity are ill-defined for causal questions; interventions must specify actionable changes (e.g., diet/exercise protocols).</li><li><strong>Conclusion from FP 3.4</strong>: Protocols with ambiguous components (e.g., surgeon experience) can yield different causal effects across studies due to treatment version variability.</li></ul></li><li><p><strong>Exchangeability</strong>: Given covariates (L), treatment assignment (A) is independent of potential outcomes (Y^a):<br> [<br> Y^a \\perp!!!\\perp A \\mid L<br> ]</p><ul><li>Holds by design in randomized experiments. In observational studies, (L) must include all confounders (variables affecting both (A) and (Y)).</li><li><strong>Threat</strong>: Unmeasured confounders (U) (e.g., smoking status in heart transplant study) violate exchangeability.</li><li><strong>Conclusion from FP 3.1</strong>: Causal effects are nonidentifiable if data are compatible with multiple effect values; exchangeability assumptions supplement data to identify effects.</li><li><strong>Conclusion from FP 3.5</strong>: Counterfactuals should be defined via interventions (&quot;possible worlds&quot; philosophy is vague; well-defined interventions are preferable).</li></ul></li><li><p><strong>Positivity</strong>: For all (l) where (\\Pr[L = l] &gt; 0), every treatment level (a) must have a positive probability:<br> [<br> \\Pr[A = a \\mid L = l] &gt; 0<br> ]</p><ul><li>Ensures data exist to estimate counterfactuals (e.g., no strata where treatment is impossible).</li><li><strong>Conclusion from TP 3.1</strong>: <ul><li>Standardization and IP weighting require positivity.</li><li>If (\\Pr[A = a \\mid L = l] = 0), standardized mean is undefined, and IP-weighted mean (E\\left[\\frac{I(A=a)Y}{f[A \\mid L]}\\right]) estimates (E[Y^a \\mid L \\in Q(a)]\\Pr[L \\in Q(a)]) (biased under exchangeability).</li></ul></li></ul></li></ol><h4 id="_3-methods-for-causal-inference" tabindex="-1"><a class="header-anchor" href="#_3-methods-for-causal-inference"><span><strong>3. Methods for Causal Inference</strong></span></a></h4><ul><li><strong>IP weighting and standardization</strong>: Estimate causal effects if identifiability conditions hold. <ul><li>E.g., For data in Table 3.1, causal risk ratio is 1 if conditions are satisfied.</li></ul></li><li><strong>Target trial framework</strong>: Specify a hypothetical randomized experiment (eligibility, interventions, outcomes) and emulate it with observational data. <ul><li><strong>Purpose</strong>: Clarifies interventions, enhances transparency, and ensures consistency.</li><li><strong>Challenges</strong>: Mismatched treatment versions (e.g., surgeons with &lt;10 transplants vs. protocol requiring ≥10) threaten consistency; collect detailed data to justify linking (Y^a) to (Y).</li></ul></li></ul><h4 id="_4-challenges-and-alternatives" tabindex="-1"><a class="header-anchor" href="#_4-challenges-and-alternatives"><span><strong>4. Challenges and Alternatives</strong></span></a></h4><ul><li><strong>Exchangeability and positivity are untestable</strong>: Rely on domain knowledge to measure sufficient (L).</li><li><strong>When identifiability conditions fail</strong>: <ul><li><strong>Instrumental variables</strong> (Chapter 16): An alternative if exchangeability given (L) is implausible.</li><li><strong>Sensitivity analyses</strong>: Assess robustness to unmeasured confounding.</li></ul></li><li><strong>Attributable fraction (FP 3.6)</strong>: <ul><li>Measures excess cases due to treatment: (\\frac{\\Pr[Y = 1] - \\Pr[Y^{a=0} = 1]}{\\Pr[Y = 1]}).</li><li>Differs from etiologic fraction (mechanically caused cases); computable only under strong assumptions.</li></ul></li><li><strong>Crossover experiments (FP 3.2)</strong>: Estimate causal effects if no carryover effects, but often implausible for long-term outcomes.</li></ul><h4 id="_5-key-conclusions-from-technical-and-fine-points" tabindex="-1"><a class="header-anchor" href="#_5-key-conclusions-from-technical-and-fine-points"><span><strong>5. Key Conclusions from Technical and Fine Points</strong></span></a></h4><ul><li><strong>FP 3.1</strong>: Causal effects are identifiable if assumptions restrict observed data to one effect value; otherwise, nonidentifiable.</li><li><strong>FP 3.2</strong>: Crossover experiments estimate average causal effects if no carryover effects, but carryover is common.</li><li><strong>FP 3.3</strong>: Avoid causal questions about states (e.g., &quot;effect of obesity&quot;); specify interventions (e.g., &quot;effect of weight-loss pill&quot;).</li><li><strong>FP 3.4</strong>: Unspecified protocol details (e.g., surgeon matching) create treatment version variability, biasing causal estimates.</li><li><strong>FP 3.5</strong>: Define counterfactuals via interventions, not &quot;closest possible worlds&quot; (lacks precision).</li><li><strong>FP 3.6</strong>: Attributable fraction quantifies excess cases from treatment; etiologic fraction requires untestable assumptions.</li><li><strong>TP 3.1</strong>: Positivity is essential for IP weighting/standardization; violations bias estimates.</li></ul><h4 id="_6-practical-implications" tabindex="-1"><a class="header-anchor" href="#_6-practical-implications"><span><strong>6. Practical Implications</strong></span></a></h4><ul><li><strong>Causal inference is assumption-dependent</strong>: Requires expert knowledge to justify identifiability conditions.</li><li><strong>Prioritize well-defined interventions</strong>: Ambiguous questions (e.g., &quot;effect of weight loss&quot;) should be refined into target trials (e.g., &quot;effect of 5% BMI reduction via diet&quot;).</li><li><strong>Observational data for prediction</strong>: If causal questions are ill-defined, use data for association/prediction (e.g., obesity predicts mortality, but causation is uncertain).</li></ul><p>This summary ensures no omission of key concepts, mathematical formalisms, or TP/FP conclusions. For implementation, always emulate a target trial to structure causal analyses.</p><hr><p>An observational study can be conceptualized as a conditionally randomized experiment under the following three conditions:</p><ul><li><p>Well-defined treatment.</p></li><li><p>The conditional prob of recieving a treatment depends only on the measured covariates.</p></li><li><p>Positivity.</p></li></ul><p>Causal inference from observational data requires two elements: <strong>data and identifiability conditions.</strong></p>',21)])])}const d=t(s,[["render",o]]),u=JSON.parse(`{"path":"/posts/Causal%20inference/What-if%20book%20reading%20notes/Chapter%203/Chapter%203.html","title":"Chapter 3","lang":"en-US","frontmatter":{"title":"Chapter 3","category":"Causal inference","tags":["Chapter 3","What-if book reading notes"],"description":"Chapter 3 Summary: Observational Studies This chapter focuses on causal inference from observational studies, contrasting them with randomized experiments. Key challenges includ...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Chapter 3\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-09-17T03:19:05.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Aaron L\\",\\"url\\":\\"https://aaronlzm.github.io\\",\\"email\\":\\"lzm_aaron@outlook.com\\"}]}"],["meta",{"property":"og:url","content":"https://aaronlzm.github.io/posts/Causal%20inference/What-if%20book%20reading%20notes/Chapter%203/Chapter%203.html"}],["meta",{"property":"og:site_name","content":"Aaron's Blog"}],["meta",{"property":"og:title","content":"Chapter 3"}],["meta",{"property":"og:description","content":"Chapter 3 Summary: Observational Studies This chapter focuses on causal inference from observational studies, contrasting them with randomized experiments. Key challenges includ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-09-17T03:19:05.000Z"}],["meta",{"property":"article:tag","content":"What-if book reading notes"}],["meta",{"property":"article:tag","content":"Chapter 3"}],["meta",{"property":"article:modified_time","content":"2025-09-17T03:19:05.000Z"}]]},"git":{"createdTime":1758079145000,"updatedTime":1758079145000,"contributors":[{"name":"lizhimou","username":"lizhimou","email":"lizhimou@bytedance.com","commits":1,"url":"https://github.com/lizhimou"}]},"readingTime":{"minutes":3.12,"words":935},"filePathRelative":"posts/Causal inference/What-if book reading notes/Chapter 3/Chapter 3.md","excerpt":"<h3>Chapter 3 Summary: Observational Studies</h3>\\n<p>This chapter focuses on causal inference from observational studies, contrasting them with randomized experiments. Key challenges include unmeasured confounding and the need for strong assumptions to estimate causal effects. The core framework involves emulating a <em>target trial</em> using observational data, relying on three <strong>identifiability conditions</strong>: exchangeability, positivity, and consistency. If these hold, methods like IP weighting or standardization can estimate causal effects. Below, I detail all main points, including conclusions from Technical Points (TP) and Fine Points (FP).</p>","autoDesc":true}`);export{d as comp,u as data};
