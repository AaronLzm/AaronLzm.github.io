import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as s,a as r,f as n,d as t,w as l,g as e,r as d,b as h}from"./app-0zlnUqcy.js";const c={};function u(g,i){const a=d("think");return h(),s("div",null,[r(a,null,{default:l(()=>[...i[0]||(i[0]=[e(' We are summarizing Chapter 13: "STANDARDIZATION AND THE PARAMETRIC G-FORMULA" from the provided text. The chapter has several sections: 13.1, 13.2, 13.3, 13.4, 13.5, and several Fine Points and Technical Points. ',-1),t("p",null,"We'll break down the chapter sections and the key points.",-1),t("p",null,"Note: The text includes tables and images that are described in the text. Since we cannot see the images, we rely on the text descriptions.",-1),t("p",null,"Steps:",-1),t("ol",null,[t("li",null,"Identify the main sections and subsections."),t("li",null,"Extract technical points and fine points as per the chapter."),t("li",null,"Follow the structure: chapter title, then subchapters, then technical points and fine points.")],-1),t("p",null,"The chapter structure as per the text:",-1),t("ul",null,[t("li",null,[e("Chapter 13: STANDARDIZATION AND THE PARAMETRIC G-FORMULA "),t("ul",null,[t("li",null,"13.1 Standardization as an alternative to IP weighting"),t("li",null,"Fine Point 13.1: Structural positivity"),t("li",null,"13.2 Estimating the mean outcome via modeling"),t("li",null,"13.3 Standardizing the mean outcome to the confounder distribution"),t("li",null,"13.4 IP weighting or standardization?"),t("li",null,"Technical Point 13.1: Bootstrapping"),t("li",null,"13.5 How seriously do we take our estimates?"),t("li",null,"Fine Point 13.2: A doubly robust plug-in estimator"),t("li",null,"Technical Point 13.2: Augmented IP weighted estimator"),t("li",null,"Technical Point 13.3: The relationship between the augmented IP weighted estimator and the doubly robust plug-in estimator")])])],-1),t("p",null,"We'll summarize each section in order.",-1),t("p",null,"Important: We must base the summary solely on the provided text and avoid adding any information not present.",-1),t("p",null,"Let's begin.",-1)])]),_:1}),i[1]||(i[1]=n(' ### Chapter 13: STANDARDIZATION AND THE PARAMETRIC G-FORMULA **Chapter Overview** This chapter introduces standardization as an alternative to IP weighting for estimating the average causal effect of smoking cessation on weight gain using observational data. Both methods rely on the same identifiability conditions but differ in modeling assumptions. The parametric g-formula is presented as a method to handle high-dimensional confounders through modeling and standardization. <hr><h4 id="_13-1-standardization-as-an-alternative-to-ip-weighting" tabindex="-1"><a class="header-anchor" href="#_13-1-standardization-as-an-alternative-to-ip-weighting"><span>13.1 Standardization as an alternative to IP weighting</span></a></h4><p><strong>Technical Points</strong>:</p><ul><li><strong>Core Theory</strong>: Standardization estimates the average causal effect (E[Y^{a=1,c=0}] - E[Y^{a=0,c=0}]) (mean weight gain if all quit smoking vs. none, with no censoring).</li><li><strong>Identifiability Conditions</strong>: Exchangeability, positivity, and consistency conditional on confounders (L) (sex, age, race, education, smoking intensity/duration, physical activity, weight).</li><li><strong>Key Formula</strong>: Standardized mean for treatment level (a):<br> [<br> \\sum_{l} E[Y \\mid A=a, C=0, L=l] \\times \\Pr[L=l]<br> ]<br> For continuous (L), replace (\\Pr[L=l]) with the probability density function (f_L(l)).</li><li><strong>Contrast with IP Weighting</strong>: <ul><li>IP weighting models (\\Pr[A=a, C=0 \\mid L]).</li><li>Standardization models (E[Y \\mid A=a, C=0, L=l]).</li></ul></li></ul><p><strong>Fine Points</strong>:</p><ul><li><strong>Structural Positivity</strong>: <ul><li>Violations (e.g., (\\Pr[A=a \\mid L=l]=0) where (\\Pr[L=l] \\neq 0)) make (E[Y \\mid A=a, L=l]) undefined.</li><li>Standardization may use parametric extrapolation to &quot;smooth over&quot; strata with structural zeroes, introducing bias but smaller standard errors than IP weighting.</li></ul></li></ul><hr><h4 id="_13-2-estimating-the-mean-outcome-via-modeling" tabindex="-1"><a class="header-anchor" href="#_13-2-estimating-the-mean-outcome-via-modeling"><span>13.2 Estimating the mean outcome via modeling</span></a></h4><p><strong>Technical Points</strong>:</p><ul><li><strong>Nonparametric Limitation</strong>: Infeasible with high-dimensional (L) (e.g., 9 confounders, 403 treated individuals across millions of strata).</li><li><strong>Parametric Approach</strong>: Linear regression model for (E[Y \\mid A=a, C=0, L=l]) with: <ul><li>Linear/quadratic terms for continuous covariates (age, weight, smoking intensity/duration).</li><li>Product term between smoking cessation ((A)) and smoking intensity.</li></ul></li><li><strong>Model Specification</strong>: Restricts conditional mean outcomes to parabolic curves and assumes covariate contributions are additive (except (A \\times) smoking intensity).</li></ul><p><strong>Fine Points</strong>:</p><ul><li><strong>Standardized Mean Integral</strong>:<br> [<br> \\int E[Y \\mid A=a, C=0, L=l] , dF_L(l)<br> ]<br> where (F_L(\\cdot)) is the joint CDF of (L).</li></ul><hr><h4 id="_13-3-standardizing-the-mean-outcome-to-the-confounder-distribution" tabindex="-1"><a class="header-anchor" href="#_13-3-standardizing-the-mean-outcome-to-the-confounder-distribution"><span>13.3 Standardizing the mean outcome to the confounder distribution</span></a></h4><p><strong>Technical Points</strong>:</p><ul><li><strong>Computational Method</strong>: <ol><li><strong>Expand dataset</strong>: Create three blocks (original data, all untreated (A=0), all treated (A=1)).</li><li><strong>Outcome modeling</strong>: Fit regression to (E[Y \\mid A, L]) using only the original data block.</li><li><strong>Prediction</strong>: Impute missing (Y) in the (A=0) and (A=1) blocks using model estimates.</li><li><strong>Standardization</strong>: Average predicted outcomes in the (A=0) and (A=1) blocks.</li></ol></li><li><strong>Result</strong>: Standardized mean for untreated = 1.66 kg; treated = 5.18 kg; causal effect = 3.52 kg (95% CI: 2.6, 4.5).</li></ul><p><strong>Fine Points</strong>:</p><ul><li><strong>Empirical Distribution</strong>: Uses observed (L) for weighting, avoiding explicit estimation of (\\Pr[L=l]).</li></ul><hr><h4 id="_13-4-ip-weighting-or-standardization" tabindex="-1"><a class="header-anchor" href="#_13-4-ip-weighting-or-standardization"><span>13.4 IP weighting or standardization?</span></a></h4><p><strong>Technical Points</strong>:</p><ul><li><strong>Equivalence</strong>: IP weighted and standardized means are identical only under nonparametric estimation.</li><li><strong>Model Misspecification Impact</strong>: <ul><li>Bias differs between methods due to different modeled quantities (treatment model vs. outcome model).</li><li>Similar estimates (e.g., 3.5 kg weight gain) suggest robustness against misspecification.</li></ul></li><li><strong>G-Formula</strong>: Standardization is a plug-in estimator of the g-formula, replacing conditional means with parametric estimates.</li></ul><p><strong>Fine Points</strong>:</p><ul><li><strong>Doubly Robust Estimators</strong>: <ul><li>Combine treatment and outcome models (e.g., augmented IP weighting, plug-in estimators).</li><li>Consistent if either model is correct (see Fine Point 13.2 and Technical Points 13.2â€“13.3).</li></ul></li></ul><hr><h4 id="_13-5-how-seriously-do-we-take-our-estimates" tabindex="-1"><a class="header-anchor" href="#_13-5-how-seriously-do-we-take-our-estimates"><span>13.5 How seriously do we take our estimates?</span></a></h4><p><strong>Technical Points</strong>:</p><ul><li><strong>Validity Requirements</strong>: <ol><li><strong>Identifiability</strong>: Exchangeability, positivity, consistency.</li><li><strong>Measurement</strong>: No error in (A), (Y), or (L).</li><li><strong>Model Specification</strong>: Correct functional forms.</li></ol></li><li><strong>Sensitivity Analysis</strong>: Essential for unverifiable assumptions (e.g., unmeasured confounding, model misspecification).</li></ul><p><strong>Fine Points</strong>:</p><ul><li><strong>Challenges</strong>: <ul><li>Unmeasured confounders, non-overlapping covariate distributions, ill-defined interventions.</li><li>Expert judgment and sensitivity analyses (e.g., quantitative bias analysis, g-estimation) mitigate limitations.</li></ul></li><li><strong>Causal Interpretation</strong>: Estimates are valid only if all conditions hold approximately.</li></ul><hr><h3 id="fine-points-and-technical-points" tabindex="-1"><a class="header-anchor" href="#fine-points-and-technical-points"><span>Fine Points and Technical Points</span></a></h3><h4 id="fine-point-13-1-structural-positivity" tabindex="-1"><a class="header-anchor" href="#fine-point-13-1-structural-positivity"><span>Fine Point 13.1: Structural Positivity</span></a></h4><ul><li><strong>Key Insight</strong>: Standardization tolerates structural non-positivity via parametric extrapolation, but bias reduces confidence interval coverage.</li></ul><h4 id="fine-point-13-2-doubly-robust-plug-in-estimator" tabindex="-1"><a class="header-anchor" href="#fine-point-13-2-doubly-robust-plug-in-estimator"><span>Fine Point 13.2: Doubly Robust Plug-in Estimator</span></a></h4><ul><li><strong>Method</strong>: <ol><li>Estimate IP weights (W^A = 1/f(A \\mid L)).</li><li>Fit outcome model (E[Y \\mid A, L, R]) with covariate (R = W^A) (if (A=1)) or (R = -W^A) (if (A=0)).</li><li>Predict standardized means under (A=1) and (A=0); difference is the causal effect.</li></ol></li></ul><h4 id="technical-point-13-1-bootstrapping" tabindex="-1"><a class="header-anchor" href="#technical-point-13-1-bootstrapping"><span>Technical Point 13.1: Bootstrapping</span></a></h4><ul><li><strong>Application</strong>: Computed 95% CI for standardized mean difference (3.5 kg) by resampling 1629 individuals 1000 times.</li></ul><h4 id="technical-point-13-2-augmented-ip-weighted-estimator" tabindex="-1"><a class="header-anchor" href="#technical-point-13-2-augmented-ip-weighted-estimator"><span>Technical Point 13.2: Augmented IP Weighted Estimator</span></a></h4>',40)),i[2]||(i[2]=t("ul",null,[t("li",null,[t("strong",null,"Formula"),e(":"),t("br"),e(" ["),t("br"),e(" \\hat{E}[Y^{a=1}]"),t("em",{i:"1"},"{DR} = \\frac{1}{n} \\sum"),e("^n \\left[ \\hat{b}(L_i) + \\frac{A_i}{\\hat{\\pi}(L_i)} (Y_i - \\hat{b}(L_i)) \\right]"),t("br"),e(" ]"),t("br"),e(" where (\\hat{b}(L)) and (\\hat{\\pi}(L)) are outcome and treatment model estimates. Asymptotically unbiased if either model is correct.")])],-1)),i[3]||(i[3]=n('<h4 id="technical-point-13-3-relationship-between-estimators" tabindex="-1"><a class="header-anchor" href="#technical-point-13-3-relationship-between-estimators"><span>Technical Point 13.3: Relationship Between Estimators</span></a></h4><ul><li><strong>Link</strong>: Augmented IP weighted and doubly robust plug-in estimators are equivalent when using iteratively reweighted least squares with a &quot;clever covariate.&quot;</li></ul><hr><h3 id="chapter-summary" tabindex="-1"><a class="header-anchor" href="#chapter-summary"><span>Chapter Summary</span></a></h3><p><strong>Logical Flow</strong>:</p><ul><li>Introduces standardization as a solution to high-dimensional confounding.</li><li>Compares it with IP weighting, highlighting modeling trade-offs.</li><li>Demonstrates practical implementation via dataset expansion and prediction.</li><li>Emphasizes causal estimate validity through sensitivity analysis and robustness checks.</li></ul><p><strong>Key Takeaway</strong>: Both standardization and IP weighting are valid under identifiability conditions, but model misspecification necessitates robustness validation via doubly robust methods or sensitivity analyses.</p>',7))])}const f=o(c,[["render",u]]),b=JSON.parse(`{"path":"/posts/Causal%20inference/What-if%20book%20reading%20notes/response_md/DeepSeek-R1-0528-2nd/Chapter_13.html","title":"Chapter_13","lang":"en-US","frontmatter":{"title":"Chapter_13","category":"Causal inference","tags":["DeepSeek-R1-0528-2nd","response_md"],"description":"### Chapter 13: STANDARDIZATION AND THE PARAMETRIC G-FORMULA **Chapter Overview** This chapter introduces standardization as an alternative to IP weighting for estimating the av...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Chapter_13\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-09-17T03:19:05.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Aaron L\\",\\"url\\":\\"https://aaronlzm.github.io\\",\\"email\\":\\"lzm_aaron@outlook.com\\"}]}"],["meta",{"property":"og:url","content":"https://aaronlzm.github.io/posts/Causal%20inference/What-if%20book%20reading%20notes/response_md/DeepSeek-R1-0528-2nd/Chapter_13.html"}],["meta",{"property":"og:site_name","content":"Aaron's Blog"}],["meta",{"property":"og:title","content":"Chapter_13"}],["meta",{"property":"og:description","content":"### Chapter 13: STANDARDIZATION AND THE PARAMETRIC G-FORMULA **Chapter Overview** This chapter introduces standardization as an alternative to IP weighting for estimating the av..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-09-17T03:19:05.000Z"}],["meta",{"property":"article:tag","content":"response_md"}],["meta",{"property":"article:tag","content":"DeepSeek-R1-0528-2nd"}],["meta",{"property":"article:modified_time","content":"2025-09-17T03:19:05.000Z"}]],"full":"2025-09-17T03:19:05.000Z"},"git":{"createdTime":1758079145000,"updatedTime":1758079145000,"contributors":[{"name":"lizhimou","username":"lizhimou","email":"lizhimou@bytedance.com","commits":1,"url":"https://github.com/lizhimou"}]},"readingTime":{"minutes":3.8,"words":1140},"filePathRelative":"posts/Causal inference/What-if book reading notes/response_md/DeepSeek-R1-0528-2nd/Chapter_13.md","excerpt":"\\n### Chapter 13: STANDARDIZATION AND THE PARAMETRIC G-FORMULA  \\n**Chapter Overview**  \\nThis chapter introduces standardization as an alternative to IP weighting for estimating the average causal effect of smoking cessation on weight gain using observational data. Both methods rely on the same identifiability conditions but differ in modeling assumptions. The parametric g-formula is presented as a method to handle high-dimensional confounders through modeling and standardization.\\n","autoDesc":true}`);export{f as comp,b as data};
