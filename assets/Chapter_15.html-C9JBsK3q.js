import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,a as s,f as a,w as r,r as l,b as c,g as p,d as e}from"./app-BpbOdWWS.js";const u={};function d(g,t){const i=l("think");return c(),o("div",null,[s(i,null,{default:r(()=>[...t[0]||(t[0]=[p(' We are summarizing Chapter 15: "OUTCOME REGRESSION AND PROPENSITY SCORES" from the provided text. The chapter has several sections: 15.1 Outcome regression, 15.2 Propensity scores, 15.3 Propensity stratification and standardization, 15.4 Propensity matching, 15.5 Propensity models, structural models, predictive models. We will follow the structure and extract the technical points and fine points as per the instructions. ',-1),e("p",null,"Note: The text includes Fine Points and Technical Points which are important for understanding.",-1),e("p",null,"Steps:",-1),e("ol",null,[e("li",null,[e("p",null,"Break down the chapter by sections and subsections.")]),e("li",null,[e("p",null,"For each section, extract:"),e("ul",null,[e("li",null,"Technical Points: core theories, key formulas, important concepts, application scenarios."),e("li",null,"Fine Points: specific cases, auxiliary information, background, nuances.")])]),e("li",null,[e("p",null,"Use Markdown and LaTeX for formulas.")])],-1),e("p",null,"Let's start with the chapter introduction and then each section.",-1)])]),_:1}),t[1]||(t[1]=a(' ### Chapter 15: OUTCOME REGRESSION AND PROPENSITY SCORES <p><strong>Introduction</strong><br> Outcome regression and propensity score methods are widely used parametric approaches for causal inference but are limited to simpler settings. They are unsuitable for time-varying treatments, which require g-methods (IP weighting, standardization, g-estimation). This chapter focuses on conventional methods applicable only to non-longitudinal data.</p><hr><h3 id="_15-1-outcome-regression" tabindex="-1"><a class="header-anchor" href="#_15-1-outcome-regression"><span>15.1 Outcome Regression</span></a></h3><p><strong>Technical Points</strong>:</p><ul><li><strong>Core Theory</strong>: Estimates causal effects by modeling the outcome conditional on treatment (A) and covariates (L). The structural model is:<br> (E[Y^{a,c=0}|L] = \\beta_0 + \\beta_1a + \\beta_2aL + \\beta_3L), where: <ul><li>(\\beta_1, \\beta_2): Parameters for causal effects of (A) on (Y) within strata of (L).</li><li>(\\beta_0, \\beta_3): Nuisance parameters quantifying the baseline mean (E[Y^{a=0,c=0}|L]).</li></ul></li><li><strong>Key Formula</strong>: Under exchangeability, positivity, and no censoring, parameters are estimable via OLS regression:<br> (E[Y|A, C=0, L] = \\alpha_0 + \\alpha_1A + \\alpha_2AL + \\alpha_3L).</li><li><strong>Important Concepts</strong>: <ul><li><strong>Nuisance Parameters</strong>: (\\beta_0, \\beta_3) lack causal interpretation and must be correctly specified to avoid bias.</li><li><strong>Effect Modification</strong>: Product terms ((aL)) capture effect heterogeneity by (L).</li></ul></li><li><strong>Application Scenarios</strong>: <ul><li>Estimating conditional causal effects within covariate strata.</li><li>Suitable for continuous or discrete outcomes (e.g., logistic regression for binary (Y)).</li></ul></li></ul><p><strong>Fine Points</strong>:</p><ul><li><strong>Misspecification Bias</strong>: Incorrect modeling of (L-Y) relationship (e.g., omitting quadratic terms) biases estimates.</li><li><strong>G-Estimation Comparison</strong>: Unlike structural nested models, outcome regression requires correct specification of the (L-Y) association but not the treatment model.</li><li><strong>Example</strong>: For smoking cessation ((A)) and weight gain ((Y)), effect estimates varied by smoking intensity (2.8 kg for 5 cigarettes/day vs. 4.4 kg for 40 cigarettes/day).</li></ul><hr><h3 id="_15-2-propensity-scores" tabindex="-1"><a class="header-anchor" href="#_15-2-propensity-scores"><span>15.2 Propensity Scores</span></a></h3><p><strong>Technical Points</strong>:</p><ul><li><strong>Core Theory</strong>: Propensity score (\\pi(L) = \\Pr[A=1|L]) balances covariates (L) between treated ((A=1)) and untreated ((A=0)) groups.</li><li><strong>Key Properties</strong>: <ul><li><strong>Balancing Score</strong>: (A \\perp!!!\\perp L \\mid \\pi(L)) (covariate distributions equalize within (\\pi(L)) strata).</li><li><strong>Sufficiency</strong>: Adjusting for (\\pi(L)) suffices if (L) ensures exchangeability.</li></ul></li><li><strong>Important Concepts</strong>: <ul><li><strong>Estimation</strong>: (\\pi(L)) is estimated via logistic regression of (A) on (L).</li><li><strong>Positivity</strong>: Requires (0 &lt; \\pi(L) &lt; 1) for all (L).</li></ul></li><li><strong>Application Scenarios</strong>: <ul><li>Replace high-dimensional (L) with scalar (\\pi(L)) for stratification, standardization, or matching.</li></ul></li></ul><p><strong>Fine Points</strong>:</p><ul><li><strong>Randomized Trials</strong>: (\\pi(L) = 0.5) for all subjects, ensuring perfect balance.</li><li><strong>Overlap</strong>: Distributions of (\\pi(L)) must overlap between treated/untreated (Figure 15.1 shows overlap in smoking cessation study).</li><li><strong>Limitation</strong>: Only balances <em>measured</em> covariates; residual confounding possible.</li></ul><hr><h3 id="_15-3-propensity-stratification-and-standardization" tabindex="-1"><a class="header-anchor" href="#_15-3-propensity-stratification-and-standardization"><span>15.3 Propensity Stratification and Standardization</span></a></h3><p><strong>Technical Points</strong>:</p><ul><li><strong>Stratification</strong>: <ul><li>Divide subjects into strata (e.g., deciles) of estimated (\\pi(L)).</li><li>Estimate causal effect within each stratum: (E[Y|A=1, C=0, \\pi(L)=s] - E[Y|A=0, C=0, \\pi(L)=s]).</li></ul></li><li><strong>Standardization</strong>: <ul><li>Fit outcome model (E[Y|A, C=0, \\pi(L)]), then standardize over (\\pi(L)) distribution.</li><li>Formula: (\\sum_s \\left( E[Y|A=1, C=0, \\pi(L)=s] - E[Y|A=0, C=0, \\pi(L)=s] \\right) \\Pr[\\pi(L)=s]).</li></ul></li><li><strong>Key Requirement</strong>: Correct specification of outcome model (e.g., linearity or splines for (\\pi(L))).</li></ul><p><strong>Fine Points</strong>:</p><ul><li><strong>Effect Modification</strong>: Including (A \\times \\pi(L)) interaction terms captures effect heterogeneity.</li><li><strong>Bias-Variance Trade-off</strong>: <ul><li>Decile-based stratification may violate exchangeability if (\\pi(L)) distributions differ within strata.</li><li>Continuous (\\pi(L)) modeling reduces bias but requires functional form correctness.</li></ul></li><li><strong>Example</strong>: Standardized effect of smoking cessation was 3.6 kg (95% CI: 2.7, 4.6).</li></ul><hr><h3 id="_15-4-propensity-matching" tabindex="-1"><a class="header-anchor" href="#_15-4-propensity-matching"><span>15.4 Propensity Matching</span></a></h3><p><strong>Technical Points</strong>:</p><ul><li><strong>Method</strong>: Match treated subjects with untreated subjects having similar (\\pi(L)) values (e.g., (\\pm 0.05)).</li><li><strong>Target Population</strong>: The matched population (e.g., effect in the treated if untreated are matched to treated).</li><li><strong>Consistency</strong>: Under exchangeability and positivity, associational measures in the matched population estimate causal effects.</li></ul><p><strong>Fine Points</strong>:</p><ul><li><strong>Closeness Criteria</strong>: <ul><li>Too loose → Poor balance → Bias.</li><li>Too tight → High exclusion → Wide confidence intervals.</li></ul></li><li><strong>Positivity Handling</strong>: Excludes subjects without matches (e.g., 2 treated with high (\\pi(L)) in smoking study).</li><li><strong>Transportability Issue</strong>: Matched populations are ill-characterized (e.g., defined by (\\pi(L)) values, not real-world variables).</li></ul><hr><h3 id="_15-5-propensity-models-structural-models-predictive-models" tabindex="-1"><a class="header-anchor" href="#_15-5-propensity-models-structural-models-predictive-models"><span>15.5 Propensity Models, Structural Models, Predictive Models</span></a></h3><p><strong>Technical Points</strong>:</p><ul><li><strong>Propensity Models</strong>: <ul><li>Model (\\Pr[A=1|L]); parameters are nuisances (non-causal).</li><li>Goal: Ensure exchangeability, not prediction accuracy.</li></ul></li><li><strong>Structural Models</strong>: <ul><li>Describe causal links (e.g., marginal structural models, structural nested models).</li><li>Parameters have causal interpretation (e.g., treatment effects).</li></ul></li><li><strong>Predictive Models</strong>: <ul><li>Forecast outcomes using associations (no causal interpretation).</li></ul></li></ul><p><strong>Fine Points</strong>:</p><ul><li><strong>Variable Selection Pitfalls</strong>: <ul><li>Including instruments or colliders in propensity models amplifies bias.</li><li>Predictive algorithms (e.g., stepwise selection) harm causal inference.</li></ul></li><li><strong>Example</strong>: Adding &quot;hospital&quot; (unnecessary covariate) to propensity models inflates variance without reducing bias.</li><li><strong>Key Insight</strong>: Causal methods require correct functional form (e.g., splines) and exchangeability/positivity.</li></ul><hr><p><strong>Logical Flow</strong>:</p><ul><li>Sections 15.1–15.4 detail methods leveraging covariates ((L)) or propensity scores ((\\pi(L))) for conditional exchangeability.</li><li>Section 15.5 contrasts these with predictive modeling, emphasizing causal inference prerequisites.</li><li>The chapter underscores limitations of conventional methods for complex (e.g., time-varying) treatments, setting up Part III&#39;s focus on g-methods.</li></ul>',35))])}const f=n(u,[["render",d]]),y=JSON.parse(`{"path":"/posts/Causal%20inference/What-if%20book%20reading%20notes/response_md/DeepSeek-R1-0528-2nd/Chapter_15.html","title":"Chapter_15","lang":"en-US","frontmatter":{"title":"Chapter_15","category":"Causal inference","tags":["DeepSeek-R1-0528-2nd","response_md"],"description":"### Chapter 15: OUTCOME REGRESSION AND PROPENSITY SCORES Introduction Outcome regression and propensity score methods are widely used parametric approaches for causal inference ...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Chapter_15\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-09-17T03:19:05.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Aaron L\\",\\"url\\":\\"https://aaronlzm.github.io\\",\\"email\\":\\"lzm_aaron@outlook.com\\"}]}"],["meta",{"property":"og:url","content":"https://aaronlzm.github.io/posts/Causal%20inference/What-if%20book%20reading%20notes/response_md/DeepSeek-R1-0528-2nd/Chapter_15.html"}],["meta",{"property":"og:site_name","content":"Aaron's Blog"}],["meta",{"property":"og:title","content":"Chapter_15"}],["meta",{"property":"og:description","content":"### Chapter 15: OUTCOME REGRESSION AND PROPENSITY SCORES Introduction Outcome regression and propensity score methods are widely used parametric approaches for causal inference ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-09-17T03:19:05.000Z"}],["meta",{"property":"article:tag","content":"response_md"}],["meta",{"property":"article:tag","content":"DeepSeek-R1-0528-2nd"}],["meta",{"property":"article:modified_time","content":"2025-09-17T03:19:05.000Z"}]]},"git":{"createdTime":1758079145000,"updatedTime":1758079145000,"contributors":[{"name":"lizhimou","username":"lizhimou","email":"lizhimou@bytedance.com","commits":1,"url":"https://github.com/lizhimou"}]},"readingTime":{"minutes":3.18,"words":954},"filePathRelative":"posts/Causal inference/What-if book reading notes/response_md/DeepSeek-R1-0528-2nd/Chapter_15.md","excerpt":"\\n### Chapter 15: OUTCOME REGRESSION AND PROPENSITY SCORES  \\n<p><strong>Introduction</strong><br>\\nOutcome regression and propensity score methods are widely used parametric approaches for causal inference but are limited to simpler settings. They are unsuitable for time-varying treatments, which require g-methods (IP weighting, standardization, g-estimation). This chapter focuses on conventional methods applicable only to non-longitudinal data.</p>","autoDesc":true}`);export{f as comp,y as data};
