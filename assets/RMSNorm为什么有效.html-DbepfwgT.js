import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as t,f as n,b as e}from"./app-BPhnXKse.js";const m={};function p(l,s){return e(),t("div",null,[...s[0]||(s[0]=[n(`<p>好的，这是一个非常深入且重要的问题。RMSNorm（Root Mean Square Normalization）是深度学习模型中一种重要的<strong>归一化技术</strong>，我们可以将其理解为对更著名的<strong>LayerNorm（层归一化）</strong> 的一个简化且高效的改进版本。</p><p>它由清华大学团队在2019年的论文《Root Mean Square Layer Normalization》中提出，并已被广泛应用于诸如LLaMA、GPT-NeoX等众多现代大语言模型中。</p><hr><h3 id="一、rmsnorm-是什么" tabindex="-1"><a class="header-anchor" href="#一、rmsnorm-是什么"><span>一、RMSNorm 是什么？</span></a></h3><h4 id="_1-核心思想" tabindex="-1"><a class="header-anchor" href="#_1-核心思想"><span>1. 核心思想</span></a></h4><p>RMSNorm的核心思想非常直观：<strong>只对输入向量的均方根（Root Mean Square, RMS）进行缩放，而不像LayerNorm那样先进行中心化（减去均值）再进行缩放。</strong></p><h4 id="_2-数学公式" tabindex="-1"><a class="header-anchor" href="#_2-数学公式"><span>2. 数学公式</span></a></h4><p>给定一个输入向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span>，LayerNorm的计算是：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>LayerNorm</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mi>μ</mi></mrow><mi>σ</mi></mfrac><mo>⋅</mo><mi>γ</mi><mo>+</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">\\text{LayerNorm}(x) = \\frac{x - \\mu}{\\sigma} \\cdot \\gamma + \\beta </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">LayerNorm</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.9463em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">μ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span></span></p><p>其中：</p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">μ</span></span></span></span> 是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 的<strong>均值</strong>。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span> 是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 的<strong>标准差</strong>。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> 是可学习的缩放和偏移参数。</li></ul><p>而RMSNorm则将其简化为：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>RMSNorm</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mi>x</mi><mrow><mtext>RMS</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>⋅</mo><mi>γ</mi></mrow><annotation encoding="application/x-tex">\\text{RMSNorm}(x) = \\frac{x}{\\text{RMS}(x)} \\cdot \\gamma </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">RMSNorm</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.0436em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1076em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">RMS</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span></span></p><p>其中：</p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>RMS</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msubsup><mi>x</mi><mi>i</mi><mn>2</mn></msubsup></mrow></msqrt></mrow><annotation encoding="application/x-tex">\\text{RMS}(x) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} x_i^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">RMS</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.84em;vertical-align:-0.6049em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2351em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7959em;"><span style="top:-2.4231em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.0448em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.1951em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.88em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.88em" viewBox="0 0 400000 1944" preserveAspectRatio="xMinYMin slice"><path d="M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6049em;"><span></span></span></span></span></span></span></span></span>，即<strong>均方根值</strong>。它衡量的是向量大小的整体水平。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span> 是<strong>可学习的缩放参数</strong>（通常省略了偏移参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span>）。</li></ul><p><strong>简单来说，RMSNorm不再计算均值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">μ</span></span></span></span> 并将数据中心化到0，而是直接使用均方根值来对数据进行缩放，使其重新调整到一个稳定的尺度上。</strong></p><hr><h3 id="二、为什么有效-layernorm的痛点与rmsnorm的解决方案" tabindex="-1"><a class="header-anchor" href="#二、为什么有效-layernorm的痛点与rmsnorm的解决方案"><span>二、为什么有效？（LayerNorm的痛点与RMSNorm的解决方案）</span></a></h3><p>要理解为什么有效，我们需要先看LayerNorm做了什么，以及RMSNorm如何对其优化。</p><h4 id="_1-重新审视layernorm的目标" tabindex="-1"><a class="header-anchor" href="#_1-重新审视layernorm的目标"><span>1. 重新审视LayerNorm的目标</span></a></h4><p>归一化的根本目的是<strong>控制数据分布的尺度和稳定性</strong>，从而缓解训练过程中的<strong>内部协变量偏移（Internal Covariate Shift）</strong> 问题，使梯度更加稳定，加快训练速度。</p><p>LayerNorm通过两个步骤实现这一目标：</p><ol><li><strong>中心化（Centering）</strong>：减去均值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">μ</span></span></span></span>。这会将数据分布的中心移动到0。</li><li><strong>缩放（Scaling）</strong>：除以标准差 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span>。这会将数据的尺度（方差）标准化为1。</li></ol><h4 id="_2-rmsnorm的洞察-中心化可能不是必须的" tabindex="-1"><a class="header-anchor" href="#_2-rmsnorm的洞察-中心化可能不是必须的"><span>2. RMSNorm的洞察：中心化可能不是必须的！</span></a></h4><p>论文作者通过实验和理论分析发现：</p><ul><li><strong>LayerNorm的成功主要来自于缩放操作（除以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span>），而非中心化操作（减去 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">μ</span></span></span></span>）。</strong></li><li><strong>减去均值的中心化操作在计算上是有开销的</strong>，它需要先计算均值，然后再从每个元素中减去它。</li><li>对于具有<strong>ReLU</strong>这类激活函数的网络（ReLU会将负值置零），分布本身就已经不是零中心的了。强行中心化到0的意义可能被后续的激活函数削弱。</li></ul><h4 id="_3-rmsnorm的有效性原理" tabindex="-1"><a class="header-anchor" href="#_3-rmsnorm的有效性原理"><span>3. RMSNorm的有效性原理</span></a></h4><ol><li><p><strong>保持了缩放不变性（Scale Invariance）</strong>：这是归一化技术起效的关键。RMSNorm通过除以RMS值，同样能够将输入向量缩放到一个单位尺度附近，从而稳定了层的输入分布，使得网络对参数的初始化和学习率不那么敏感。这带来了稳定的梯度和更快的训练速度。</p></li><li><p><strong>计算效率更高</strong>：</p><ul><li>计算量更小：RMSNorm省去了计算均值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">μ</span></span></span></span> 和方差 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>σ</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\\sigma^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>（方差计算也需要均值）的步骤。</li><li>根据论文，RMSNorm比LayerNorm<strong>减少了约7%～64%的计算时间</strong>。在大规模模型中，这点微小的效率提升累积起来是非常可观的。</li></ul></li><li><p><strong>性能不相上下甚至更好</strong>：</p><ul><li>论文在多个任务（语言模型、图像分类、机器翻译）上进行了实验，发现RMSNorm的表现与LayerNorm<strong>相当甚至更好</strong>。</li><li>这表明，<strong>减去均值的中心化操作所提供的收益，在很多情况下可以被省略，而不会损害模型的表达能力</strong>。简化后的操作反而可能让模型更专注于学习真正重要的模式。</li></ul></li></ol><hr><h3 id="三、总结与对比" tabindex="-1"><a class="header-anchor" href="#三、总结与对比"><span>三、总结与对比</span></a></h3><table><thead><tr><th style="text-align:left;">特性</th><th style="text-align:left;">LayerNorm</th><th style="text-align:left;">RMSNorm</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>核心操作</strong></td><td style="text-align:left;"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><mi>μ</mi><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mi>σ</mi></mrow><annotation encoding="application/x-tex">(x - \\mu) / \\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">μ</span><span class="mclose">)</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span></td><td style="text-align:left;"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mi mathvariant="normal">/</mi><mtext>RMS</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x / \\text{RMS}(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mord">/</span><span class="mord text"><span class="mord">RMS</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></td></tr><tr><td style="text-align:left;"><strong>是否中心化</strong></td><td style="text-align:left;">是</td><td style="text-align:left;"><strong>否</strong></td></tr><tr><td style="text-align:left;"><strong>计算开销</strong></td><td style="text-align:left;">较高（需算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">μ</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span>）</td><td style="text-align:left;"><strong>较低</strong>（只需算RMS）</td></tr><tr><td style="text-align:left;"><strong>可学习参数</strong></td><td style="text-align:left;"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> (缩放和偏移)</td><td style="text-align:left;"><strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span></span></span></span> (仅缩放)</strong></td></tr><tr><td style="text-align:left;"><strong>效果</strong></td><td style="text-align:left;">深度学习的基础，非常有效</td><td style="text-align:left;"><strong>效果相当，有时更优</strong></td></tr><tr><td style="text-align:left;"><strong>流行度</strong></td><td style="text-align:left;">Transformer、BERT等经典模型</td><td style="text-align:left;"><strong>LLaMA、GPT-NeoX等新锐模型</strong></td></tr></tbody></table><h3 id="为什么现在这么流行" tabindex="-1"><a class="header-anchor" href="#为什么现在这么流行"><span>为什么现在这么流行？</span></a></h3><p>RMSNorm的流行与大规模语言模型的发展紧密相关：</p><ol><li><strong>效率至上</strong>：训练一个千亿参数的模型成本极高，任何能节省计算开销（即使是几个百分点）而又不损失性能的方法都极具吸引力。</li><li><strong>实践验证</strong>：像LLaMA这样的顶级模型选择了RMSNorm，并用其卓越的性能证明了这种简化归一化的有效性，从而带动了整个业界的采纳。</li></ol><p><strong>总而言之，RMSNorm的有效性在于它抓住了归一化问题的关键——缩放（Scaling），并巧妙地移除了可能非必要的中心化（Centering）步骤，从而在保持甚至提升模型表现的同时，实现了更高的计算效率。它是一种“如无必要，勿增实体”奥卡姆剃刀原则在深度学习中的完美体现。</strong>��在深度学习中的完美体现。**</p>`,35)])])}const o=a(m,[["render",p]]),c=JSON.parse(`{"path":"/posts/machine_learning/trick_layers/tricks/RMSNorm%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%95%88.html","title":"RMSNorm为什么有效","lang":"en-US","frontmatter":{"title":"RMSNorm为什么有效","category":"Machine Learning","tags":["Machine Learning","tricks"],"description":"好的，这是一个非常深入且重要的问题。RMSNorm（Root Mean Square Normalization）是深度学习模型中一种重要的归一化技术，我们可以将其理解为对更著名的LayerNorm（层归一化） 的一个简化且高效的改进版本。 它由清华大学团队在2019年的论文《Root Mean Square Layer Normalization》中...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"RMSNorm为什么有效\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-09-16T12:31:49.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Aaron L\\",\\"url\\":\\"https://aaronlzm.github.io\\",\\"email\\":\\"lzm_aaron@outlook.com\\"}]}"],["meta",{"property":"og:url","content":"https://aaronlzm.github.io/posts/machine_learning/trick_layers/tricks/RMSNorm%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%95%88.html"}],["meta",{"property":"og:site_name","content":"Aaron's Blog"}],["meta",{"property":"og:title","content":"RMSNorm为什么有效"}],["meta",{"property":"og:description","content":"好的，这是一个非常深入且重要的问题。RMSNorm（Root Mean Square Normalization）是深度学习模型中一种重要的归一化技术，我们可以将其理解为对更著名的LayerNorm（层归一化） 的一个简化且高效的改进版本。 它由清华大学团队在2019年的论文《Root Mean Square Layer Normalization》中..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-09-16T12:31:49.000Z"}],["meta",{"property":"article:tag","content":"tricks"}],["meta",{"property":"article:tag","content":"Machine Learning"}],["meta",{"property":"article:modified_time","content":"2025-09-16T12:31:49.000Z"}]]},"git":{"createdTime":1757508567000,"updatedTime":1758025909000,"contributors":[{"name":"lizhimou","username":"lizhimou","email":"lizhimou@bytedance.com","commits":3,"url":"https://github.com/lizhimou"}]},"readingTime":{"minutes":4.51,"words":1353},"filePathRelative":"posts/machine_learning/trick&layers/tricks/RMSNorm为什么有效.md","excerpt":"<p>好的，这是一个非常深入且重要的问题。RMSNorm（Root Mean Square Normalization）是深度学习模型中一种重要的<strong>归一化技术</strong>，我们可以将其理解为对更著名的<strong>LayerNorm（层归一化）</strong> 的一个简化且高效的改进版本。</p>\\n<p>它由清华大学团队在2019年的论文《Root Mean Square Layer Normalization》中提出，并已被广泛应用于诸如LLaMA、GPT-NeoX等众多现代大语言模型中。</p>","autoDesc":true}`);export{o as comp,c as data};
