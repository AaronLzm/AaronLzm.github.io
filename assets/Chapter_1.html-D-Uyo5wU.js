import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,a as s,f as r,w as l,r as c,b as u,g as t,d as e}from"./app-CQuKQiHV.js";const d={};function p(h,i){const a=c("think");return u(),o("div",null,[s(a,null,{default:l(()=>[...i[0]||(i[0]=[t(' We are summarizing Chapter 1 of the book "Causal Inference: What If" by Hernán and Robins. The chapter is titled "A DEFINITION OF CAUSAL EFFECT" ',-1),e("p",null,"We are going to break down the chapter into its sections and subsections, and extract the technical points and fine points as per the instructions.",-1),e("p",null,[t("The chapter has the following sections (as per the provided text):"),e("br"),t(" 1.1 Individual causal effects"),e("br"),t(" 1.2 Average causal effects"),e("br"),t(" 1.3 Measures of causal effect"),e("br"),t(" 1.4 Random variability"),e("br"),t(" 1.5 Causation versus association")],-1),e("p",null,'Additionally, there are two "Fine Points" (1.1 and 1.2) and one "Technical Point" (1.1) embedded in the text.',-1),e("p",null,"We note that the text also has a table (Table 1.1) and a figure (Figure 1.1) that we will describe based on the context.",-1),e("p",null,"Steps:",-1),e("ol",null,[e("li",null,"We will go through each section and extract the key concepts, definitions, and examples."),e("li",null,"We will note the mathematical notation and formulas, using LaTeX when required."),e("li",null,"We will summarize the Fine Points and Technical Points as separate subsections under the relevant sections.")],-1),e("p",null,"Let's start with the introduction and then each section.",-1)])]),_:1}),i[1]||(i[1]=r(' ### Chapter 1: A DEFINITION OF CAUSAL EFFECT <h4 id="introduction" tabindex="-1"><a class="header-anchor" href="#introduction"><span>Introduction</span></a></h4><p>The chapter formalizes intuitive causal concepts using mathematical notation. Humans inherently understand causal effects by comparing outcomes under different actions (e.g., &quot;What if I had acted differently?&quot;). The goal is to match this intuition with formal definitions for precise causal inference.</p><h4 id="_1-1-individual-causal-effects" tabindex="-1"><a class="header-anchor" href="#_1-1-individual-causal-effects"><span>1.1 Individual Causal Effects</span></a></h4><p><strong>Technical Points</strong>:</p><ul><li><strong>Core Theory</strong>: An individual causal effect exists if the outcome under treatment ((A = 1)) differs from the outcome under no treatment ((A = 0)).</li><li><strong>Key Notation</strong>: <ul><li>(A): Dichotomous treatment variable (1 = treated, 0 = untreated).</li><li>(Y): Dichotomous outcome variable (1 = death, 0 = survival).</li><li>(Y^{a=1}): Counterfactual outcome if treated.</li><li>(Y^{a=0}): Counterfactual outcome if untreated.</li></ul></li><li><strong>Causal Effect Definition</strong>: For individual (i), treatment (A) has a causal effect if (Y^{a=1}_i \\neq Y^{a=0}_i).</li><li><strong>Consistency Principle</strong>: If observed treatment (A_i = a), then observed outcome (Y_i = Y^a_i).</li></ul><p><strong>Fine Points</strong>:</p><ul><li><strong>Counterfactual Terminology</strong>: <ul><li><em>Potential outcomes</em>: Emphasizes observability under different treatments.</li><li><em>Counterfactual outcomes</em>: Emphasizes hypothetical scenarios.</li></ul></li><li><strong>Missing Data Challenge</strong>: Individual causal effects cannot be directly observed because only one counterfactual outcome is factual (consistency), while the other remains unobserved.</li></ul><hr><h4 id="_1-2-average-causal-effects" tabindex="-1"><a class="header-anchor" href="#_1-2-average-causal-effects"><span>1.2 Average Causal Effects</span></a></h4><p><strong>Technical Points</strong>:</p><ul><li><strong>Core Theory</strong>: When individual effects are unidentifiable, aggregate effects over a population are used. An average causal effect exists if the expected outcomes under different treatments differ.</li><li><strong>Key Formula</strong>: <ul><li>Average causal effect: (E[Y^{a=1}] \\neq E[Y^{a=0}]).</li><li>For binary (Y), (E[Y^a] = \\Pr(Y^a = 1)).</li></ul></li><li><strong>Null Hypothesis</strong>: No average effect if (\\Pr(Y^{a=1} = 1) = \\Pr(Y^{a=0} = 1)).</li></ul><p><strong>Fine Points</strong>:</p><ul><li><strong>Interference (Fine Point 1.1)</strong>: <ul><li>Assumption: An individual’s outcome depends only on their own treatment (no interference).</li><li>Violation Example: Zeus’s survival may depend on Hera’s transplant status.</li><li>SUTVA (Stable Unit Treatment Value Assumption) includes no interference.</li></ul></li><li><strong>Multiple Treatment Versions (Fine Point 1.2)</strong>: <ul><li>Assumption: Only one version of treatment (A = a) exists.</li><li>Violation Example: Surgical outcomes depend on surgeon skill.</li><li>Resolution: &quot;Treatment variation irrelevance&quot; assumes all versions have identical outcomes.</li></ul></li></ul><p><strong>Details from Table 1.1</strong>:</p><ul><li>Population: 20 individuals with counterfactual outcomes under treatment/no treatment.</li><li>(\\Pr(Y^{a=1} = 1) = 10/20 = 0.5), (\\Pr(Y^{a=0} = 1) = 10/20 = 0.5) → No average causal effect.</li><li>Individual effects: 12/20 individuals had (Y^{a=1} \\neq Y^{a=0}) (6 harmed, 6 helped).</li></ul><hr><h4 id="_1-3-measures-of-causal-effect" tabindex="-1"><a class="header-anchor" href="#_1-3-measures-of-causal-effect"><span>1.3 Measures of Causal Effect</span></a></h4><p><strong>Technical Points</strong>:</p><ul><li><strong>Effect Measures</strong>: <ul><li>Causal Risk Difference (RD): (\\Pr(Y^{a=1} = 1) - \\Pr(Y^{a=0} = 1)).</li><li>Causal Risk Ratio (RR): (\\Pr(Y^{a=1} = 1) / \\Pr(Y^{a=0} = 1)).</li><li>Causal Odds Ratio (OR): (\\frac{\\Pr(Y^{a=1} = 1)/\\Pr(Y^{a=1} = 0)}{\\Pr(Y^{a=0} = 1)/\\Pr(Y^{a=0} = 0)}).</li></ul></li><li><strong>Null Representation</strong>: All measures equal 0 (RD), 1 (RR, OR) under no effect.</li></ul><p><strong>Fine Points</strong>:</p><ul><li><strong>Number Needed to Treat (NNT) (Fine Point 1.3)</strong>: <ul><li>Definition: Average individuals needed to treat to prevent one adverse outcome.</li><li>Formula: (\\text{NNT} = -1 / \\text{RD}) (if RD &lt; 0).</li><li>Example: RD = -0.1 → NNT = 10.</li></ul></li><li><strong>Scale Dependence</strong>: <ul><li>RR (multiplicative) quantifies relative risk change.</li><li>RD (additive) quantifies absolute case reduction.</li></ul></li></ul><p><strong>Technical Point 1.1</strong>:</p><ul><li>Population causal effects can extend beyond means (e.g., variance, median), but nonlinear measures (e.g., (\\text{Var}(Y^{a=1}) - \\text{Var}(Y^{a=0}))) are not equal to the variance of individual effects.</li></ul><hr><h4 id="_1-4-random-variability" tabindex="-1"><a class="header-anchor" href="#_1-4-random-variability"><span>1.4 Random Variability</span></a></h4><p><strong>Technical Points</strong>:</p><ul><li><strong>Sources of Random Error</strong>: <ol><li><strong>Sampling Variability</strong>: Sample proportions (e.g., (\\widehat{\\Pr}(Y^a = 1))) estimate super-population probabilities.</li><li><strong>Nondeterministic Counterfactuals</strong>: Outcomes may be stochastic (e.g., Zeus has 90% chance of death if treated).</li></ol></li><li><strong>Consistency of Estimators</strong>: (\\widehat{\\Pr}(Y^a = 1)) is consistent for (\\Pr(Y^a = 1)) as sample size → ∞.</li></ul><p><strong>Fine Points</strong>:</p><ul><li><strong>Nondeterministic Counterfactuals (Technical Point 1.2)</strong>: <ul><li>(Y^a) follows an individual-specific distribution (\\Theta_{Y^a}(\\cdot)).</li><li>Mean outcome: (E[Y^a] = \\int y dF_{Y^a}(y)).</li><li>Binary case: Causal RR equals weighted average of individual RRs.</li></ul></li><li><strong>Assumption for Simplicity</strong>: Until Chapter 10, counterfactuals are treated as deterministic.</li></ul><hr><h4 id="_1-5-causation-versus-association" tabindex="-1"><a class="header-anchor" href="#_1-5-causation-versus-association"><span>1.5 Causation versus Association</span></a></h4><p><strong>Technical Points</strong>:</p><ul><li><strong>Association</strong>: Defined by conditional probabilities in the observed world. <ul><li>Independence: (Y \\perp!!!\\perp A) if (\\Pr(Y = 1 | A = 1) = \\Pr(Y = 1 | A = 0)).</li><li>Measures: Associational RD, RR, OR (parallel to causal measures).</li></ul></li><li><strong>Key Distinction</strong>: <ul><li>Causation: Contrasts marginal risks in the same population under different treatments (e.g., (\\Pr(Y^{a=1} = 1)) vs. (\\Pr(Y^{a=0} = 1))).</li><li>Association: Contrasts conditional risks in disjoint subgroups (e.g., (\\Pr(Y = 1 | A = 1)) vs. (\\Pr(Y = 1 | A = 0))).</li></ul></li></ul><p><strong>Fine Points</strong>:</p><ul><li><strong>Example from Table 1.2</strong>: <ul><li>Association: (\\Pr(Y = 1 | A = 1) = 7/13), (\\Pr(Y = 1 | A = 0) = 3/7) → Association exists.</li><li>Causation: (\\Pr(Y^{a=1} = 1) = \\Pr(Y^{a=0} = 1) = 0.5) → No causal effect.</li></ul></li><li><strong>Confounding</strong>: Discrepancy arises due to imbalanced baseline risk (e.g., sicker patients receive treatment).</li></ul><p><strong>Figure 1.1 Summary</strong>:</p><ul><li>Visualizes causation (whole population under two treatments) vs. association (treated vs. untreated subgroups).</li></ul><hr><h3 id="chapter-logic-and-coherence" tabindex="-1"><a class="header-anchor" href="#chapter-logic-and-coherence"><span>Chapter Logic and Coherence</span></a></h3><p>This chapter establishes foundational concepts:</p><ol><li><strong>Individual counterfactuals</strong> define causality but are unobservable.</li><li><strong>Average causal effects</strong> resolve unidentifiability by aggregating over populations.</li><li><strong>Measures</strong> (RD, RR, OR, NNT) quantify effect size on different scales.</li><li><strong>Random variability</strong> (sampling, nondeterminism) complicates estimation.</li><li><strong>Association ≠ Causation</strong> due to confounding, motivating causal inference methods (e.g., randomization, discussed in Chapter 2).</li></ol><p>All conclusions are derived from the provided text, with mathematical extensions (e.g., expectations for continuous outcomes) explicitly grounded in Technical Points.</p>',43))])}const g=n(d,[["render",p]]),v=JSON.parse(`{"path":"/posts/Causal%20inference/What-if%20book%20reading%20notes/response_md/DeepSeek-R1-0528-2nd/Chapter_1.html","title":"Chapter_1","lang":"en-US","frontmatter":{"title":"Chapter_1","category":"Causal inference","tags":["DeepSeek-R1-0528-2nd","response_md"],"description":"### Chapter 1: A DEFINITION OF CAUSAL EFFECT Introduction The chapter formalizes intuitive causal concepts using mathematical notation. Humans inherently understand causal effec...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Chapter_1\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-09-17T03:19:05.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Aaron L\\",\\"url\\":\\"https://aaronlzm.github.io\\",\\"email\\":\\"lzm_aaron@outlook.com\\"}]}"],["meta",{"property":"og:url","content":"https://aaronlzm.github.io/posts/Causal%20inference/What-if%20book%20reading%20notes/response_md/DeepSeek-R1-0528-2nd/Chapter_1.html"}],["meta",{"property":"og:site_name","content":"Aaron's Blog"}],["meta",{"property":"og:title","content":"Chapter_1"}],["meta",{"property":"og:description","content":"### Chapter 1: A DEFINITION OF CAUSAL EFFECT Introduction The chapter formalizes intuitive causal concepts using mathematical notation. Humans inherently understand causal effec..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-09-17T03:19:05.000Z"}],["meta",{"property":"article:tag","content":"response_md"}],["meta",{"property":"article:tag","content":"DeepSeek-R1-0528-2nd"}],["meta",{"property":"article:modified_time","content":"2025-09-17T03:19:05.000Z"}]]},"git":{"createdTime":1758079145000,"updatedTime":1758079145000,"contributors":[{"name":"lizhimou","username":"lizhimou","email":"lizhimou@bytedance.com","commits":1,"url":"https://github.com/lizhimou"}]},"readingTime":{"minutes":3.66,"words":1099},"filePathRelative":"posts/Causal inference/What-if book reading notes/response_md/DeepSeek-R1-0528-2nd/Chapter_1.md","excerpt":"\\n### Chapter 1: A DEFINITION OF CAUSAL EFFECT\\n<h4>Introduction</h4>\\n<p>The chapter formalizes intuitive causal concepts using mathematical notation. Humans inherently understand causal effects by comparing outcomes under different actions (e.g., \\"What if I had acted differently?\\"). The goal is to match this intuition with formal definitions for precise causal inference.</p>","autoDesc":true}`);export{g as comp,v as data};
