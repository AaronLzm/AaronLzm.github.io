import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as i,f as a,b as o}from"./app-DEYtLtpW.js";const s={};function n(r,e){return o(),i("div",null,[...e[0]||(e[0]=[a('<p>At its heart, a diffusion model is a generative model, which means its primary purpose is to create new data that is similar to the data it was trained on. In the context of images, this means generating new, realistic-looking pictures. The core idea behind diffusion models is both elegant and surprisingly intuitive: <strong>to learn how to create data, you should first learn how to destroy it.</strong></p><p>The entire process can be broken down into two main stages: the <strong>forward process</strong> and the <strong>reverse process</strong>.</p><h3 id="the-forward-process-systematically-destroying-an-image" tabindex="-1"><a class="header-anchor" href="#the-forward-process-systematically-destroying-an-image"><span>The Forward Process: Systematically Destroying an Image</span></a></h3><p>The forward process, also known as the diffusion process, is the &quot;destruction&quot; phase. It&#39;s a fixed procedure, meaning it doesn&#39;t involve any learning. Here&#39;s what happens step-by-step:</p><ol><li><strong>Start with a real image</strong> from your training dataset (e.g., a picture of a cat).</li><li><strong>Gradually add a small amount of Gaussian noise</strong> to the image. Gaussian noise is a type of random statistical noise that follows a bell curve distribution, often resembling static on an old television.</li><li><strong>Repeat this process</strong> over and over again, adding a little more noise at each step. This is done for a predefined number of timesteps, often denoted as <code>T</code> (which could be, for example, 1000).</li></ol><p>The key here is that the noise is added in a controlled manner. We know exactly how much noise is being added at each timestep. As you progress through these timesteps, the original image becomes increasingly corrupted. By the final timestep <code>T</code>, the image is indistinguishable from pure, random noise.</p><p>Think of it like adding a drop of black ink to a glass of clear water every second. Initially, you can still see through the water, but after many drops, the water becomes completely opaque. The forward process is this journey from a clear image to pure noise.</p><h3 id="the-reverse-process-learning-to-recreate-the-image" tabindex="-1"><a class="header-anchor" href="#the-reverse-process-learning-to-recreate-the-image"><span>The Reverse Process: Learning to Recreate the Image</span></a></h3><p>This is where the magic and the machine learning happen. The goal of the reverse process is to undo the forward process. It starts with random noise and gradually removes it to generate a clean, coherent image.</p><p>To do this, we need a powerful neural network. In most modern diffusion models, this is a <strong>U-Net architecture</strong>. Here&#39;s how it&#39;s trained and what it does:</p><ol><li><strong>Input:</strong> The U-Net is given a noisy image from a specific point in the forward process (say, the image at timestep <code>t</code>).</li><li><strong>The Goal:</strong> Its task is not to directly guess the final clean image. Instead, it is trained to <strong>predict the noise</strong> that was added to the image at that particular timestep <code>t</code>.</li><li><strong>Training:</strong> We can train this network because we know the original image and we know exactly how much noise was added at each step in the forward process. So, we can give the network the noisy image and ask it to predict the noise. We then compare its prediction to the actual noise that was added and adjust the network&#39;s parameters to make its prediction more accurate. This is repeated for countless images at all possible timesteps.</li></ol><h3 id="generating-a-new-image" tabindex="-1"><a class="header-anchor" href="#generating-a-new-image"><span>Generating a New Image</span></a></h3><p>Once the U-Net is well-trained, we can use it to generate new images from scratch:</p><ol><li><strong>Start with Pure Noise:</strong> We generate a random image that is pure Gaussian noise. This is our starting point at timestep <code>T</code>.</li><li><strong>Iterative Denoising:</strong><ul><li>We feed this noisy image into our trained U-Net and also tell it that we are at timestep <code>T</code>.</li><li>The U-Net analyzes the image and predicts the noise component within it.</li><li>We then subtract a small amount of this predicted noise from the image. This gives us a slightly less noisy image, corresponding to the image at timestep <code>T-1</code>.</li></ul></li><li><strong>Repeat:</strong> We take this new, slightly cleaner image, tell the U-Net we are now at timestep <code>T-1</code>, and repeat the process. The U-Net again predicts the noise, and we subtract it.</li><li><strong>Final Image:</strong> We continue this iterative denoising process all the way down to timestep <code>t=0</code>. By this point, if the model is well-trained, we will have a clean, realistic-looking image that is entirely new but shares the characteristics of the images the model was trained on.</li></ol><p>In essence, the diffusion model learns the path from noise back to a clear image by mastering the art of predicting and removing that noise, one small step at a time. This gradual, step-by-step refinement is what allows these models to generate such incredibly detailed and coherent images.e such incredibly detailed and coherent images.</p>',15)])])}const h=t(s,[["render",n]]),c=JSON.parse(`{"path":"/posts/Machine_learning/diffusers/How%20does%20diffusion%20model%20work.html","title":"How does diffusion model work","lang":"en-US","frontmatter":{"title":"How does diffusion model work","category":"Machine Learning","tags":["Machine Learning","diffusers"],"description":"At its heart, a diffusion model is a generative model, which means its primary purpose is to create new data that is similar to the data it was trained on. In the context of ima...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"How does diffusion model work\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-11-25T05:15:08.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Aaron L\\",\\"url\\":\\"https://aaronlzm.github.io\\",\\"email\\":\\"lzm_aaron@outlook.com\\"}]}"],["meta",{"property":"og:url","content":"https://aaronlzm.github.io/posts/Machine_learning/diffusers/How%20does%20diffusion%20model%20work.html"}],["meta",{"property":"og:site_name","content":"Aaron's Blog"}],["meta",{"property":"og:title","content":"How does diffusion model work"}],["meta",{"property":"og:description","content":"At its heart, a diffusion model is a generative model, which means its primary purpose is to create new data that is similar to the data it was trained on. In the context of ima..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-11-25T05:15:08.000Z"}],["meta",{"property":"article:tag","content":"diffusers"}],["meta",{"property":"article:tag","content":"Machine Learning"}],["meta",{"property":"article:modified_time","content":"2025-11-25T05:15:08.000Z"}]]},"git":{"createdTime":1757508567000,"updatedTime":1764047708000,"contributors":[{"name":"lizhimou","username":"lizhimou","email":"lizhimou@bytedance.com","commits":6,"url":"https://github.com/lizhimou"}]},"readingTime":{"minutes":2.64,"words":792},"filePathRelative":"posts/Machine_learning/diffusers/How does diffusion model work.md","excerpt":"<p>At its heart, a diffusion model is a generative model, which means its primary purpose is to create new data that is similar to the data it was trained on. In the context of images, this means generating new, realistic-looking pictures. The core idea behind diffusion models is both elegant and surprisingly intuitive: <strong>to learn how to create data, you should first learn how to destroy it.</strong></p>","autoDesc":true}`);export{h as comp,c as data};
