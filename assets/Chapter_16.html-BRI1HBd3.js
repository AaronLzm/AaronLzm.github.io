import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,a as s,f as r,w as l,r as u,b as c,g as t,d as e}from"./app-DkbOixE-.js";const d={};function m(g,i){const n=u("think");return c(),a("div",null,[s(n,null,{default:l(()=>[...i[0]||(i[0]=[t(` We are summarizing Chapter 16 "Instrumental Variable Estimation" from the provided PDF content. The chapter has several sections and technical points. We'll break it down step by step. `,-1),e("p",null,"Steps:",-1),e("ol",null,[e("li",null,"Identify the main sections and subsections."),e("li",null,"Extract technical points and fine points."),e("li",null,[t("Summarize the content by section, focusing on: "),e("ul",null,[e("li",null,"Technical Points: core theories, key formulas, important concepts, application scenarios."),e("li",null,"Fine Points: specific examples, auxiliary information, background, and details.")])])],-1),e("p",null,"Note: We cannot interpret images, so we rely on the text descriptions and context.",-1),e("p",null,"Chapter Structure:",-1),e("ul",null,[e("li",null,"16.1 The three instrumental conditions"),e("li",null,"Technical Point 16.1: The instrumental conditions, formally."),e("li",null,"Fine Point 16.1: Candidate instruments in observational studies."),e("li",null,"16.2 The usual IV estimand"),e("li",null,"Technical Point 16.2: Bounds: Partial identification of causal effects."),e("li",null,"Technical Point 16.3: Additive structural mean models and IV estimation."),e("li",null,"Technical Point 16.4: Multiplicative structural mean models and IV estimation."),e("li",null,"16.3 A fourth identifying condition: homogeneity"),e("li",null,"Technical Point 16.5: Proof of the general homogeneity condition."),e("li",null,"16.4 An alternative fourth condition: monotonicity"),e("li",null,"Technical Point 16.6: More general structural mean models."),e("li",null,"Technical Point 16.7: Monotonicity and the effect in the compliers."),e("li",null,"16.5 The three instrumental conditions revisited"),e("li",null,"Fine Point 16.2: Defining weak instruments."),e("li",null,"16.6 Instrumental variable estimation versus other methods"),e("li",null,"Fine Point 16.3: Regression discontinuity design.")],-1),e("p",null,"We'll proceed section by section, including the technical and fine points in their respective sections.",-1),e("p",null,"Important: We must use LaTeX for formulas and markdown formatting.",-1)])]),_:1}),i[1]||(i[1]=r(' ### Chapter 16: INSTRUMENTAL VARIABLE ESTIMATION **Introduction** - Causal inference methods previously discussed require measuring all confounders, but residual bias persists if unmeasured confounders exist. - Instrumental variable (IV) estimation offers an alternative approach under different assumptions, avoiding the need to measure all confounders. <hr><h4 id="_16-1-the-three-instrumental-conditions" tabindex="-1"><a class="header-anchor" href="#_16-1-the-three-instrumental-conditions"><span>16.1 The three instrumental conditions</span></a></h4><p><strong>Subchapter Content</strong></p><ul><li><strong>Causal diagram (Figure 16.1)</strong>: Depicts a double-blind randomized trial where: <ul><li>(Z): Randomization assignment (1: treatment, 0: placebo).</li><li>(A): Actual treatment received (non-adherence possible).</li><li>(Y): Outcome.</li><li>(U): Unmeasured factors affecting both (A) and (Y).</li></ul></li><li><strong>Problem</strong>: Standard methods (IP weighting, standardization, etc.) require adjusting for (U) to block backdoor path (A \\leftarrow U \\rightarrow Y).</li><li><strong>IV solution</strong>: Uses an instrumental variable (Z) meeting three conditions:<br> (i) (Z) is associated with (A) (relevance).<br> (ii) (Z) affects (Y) only through (A) (exclusion restriction).<br> (iii) (Z) and (Y) share no common causes (exchangeability).</li><li><strong>Observational example</strong>: Cigarette price as a candidate instrument for smoking cessation ((A)) and weight change ((Y)). Only condition (i) is empirically verifiable.</li></ul><p><strong>Technical Points (Technical Point 16.1)</strong></p><ul><li><strong>Formal definitions</strong>: <ul><li>(i) Relevance: (Z \\not!\\perp!!!\\perp A) (non-null association).</li><li>(ii) Exclusion restriction: (Y^{z,a} = Y^{a}) (no direct effect of (Z) on (Y)).</li><li>(iii) Exchangeability: (Y^{a,z} \\perp!!!\\perp Z) (marginal or joint).</li></ul></li><li><strong>Instrument types</strong>: <ul><li><em>Causal instrument</em>: (Z) directly affects (A) (Figure 16.1).</li><li><em>Surrogate instrument</em>: Proxy for unmeasured causal instrument (U_Z) (Figures 16.2, 16.3).</li></ul></li></ul><p><strong>Fine Points (Fine Point 16.1)</strong></p><ul><li><strong>Candidate instruments in observational studies</strong>: <ul><li><em>Genetic factors</em>: e.g., ALDH2 polymorphism for alcohol effects (Mendelian randomization).</li><li><em>Preference</em>: Physician’s prescribing preference (e.g., last prescription issued).</li><li><em>Access</em>: Physical distance to facility or calendar period.</li></ul></li><li><strong>Weak instrument</strong>: Defined by small (Z)-(A) association (e.g., risk difference = 6%).</li></ul><hr><h4 id="_16-2-the-usual-iv-estimand" tabindex="-1"><a class="header-anchor" href="#_16-2-the-usual-iv-estimand"><span>16.2 The usual IV estimand</span></a></h4><p><strong>Subchapter Content</strong></p><ul><li><strong>IV estimand for dichotomous (Z)</strong>:<br> [<br> \\frac{E[Y|Z=1] - E[Y|Z=0]}{E[A|Z=1] - E[A|Z=0]}<br> ]</li><li><strong>Intuition</strong>: Numerator = intent-to-treat effect of (Z) on (Y); denominator = effect of (Z) on (A) (adherence).</li><li><strong>Estimation</strong>: <ul><li>Standard IV estimator: Ratio of sample averages.</li><li>Two-stage least squares: <ol><li>Fit (E[A|Z] = \\alpha_0 + \\alpha_1 Z), predict (\\hat{A}).</li><li>Fit (E[Y|Z] = \\beta_0 + \\beta_1 \\hat{A}); (\\hat{\\beta}_1) = IV estimate.</li></ol></li></ul></li><li><strong>Example</strong>: Smoking cessation ((A)) and weight gain ((Y)) with price instrument ((Z)): <ul><li>Estimate = 2.4 kg (95% CI: -36.5 to 41.3), indicating weak instrument issues.</li></ul></li></ul><p><strong>Technical Points (Technical Point 16.2, 16.3, 16.4)</strong></p><ul><li><strong>Partial identification</strong>: Bounds for causal effects can be narrowed using IVs but often remain wide/uninformative.</li><li><strong>Structural mean models</strong>: <ul><li><em>Additive</em>: (E[Y - Y^{a=0}|A,Z] = A(\\beta_0 + \\beta_1 Z)). <ul><li>Usual IV estimand = (\\beta_0) under no effect modification by (Z) ((\\beta_1=0)).</li></ul></li><li><em>Multiplicative</em>: Identifies causal risk ratios under multiplicative homogeneity.</li></ul></li></ul><hr><h4 id="_16-3-a-fourth-identifying-condition-homogeneity" tabindex="-1"><a class="header-anchor" href="#_16-3-a-fourth-identifying-condition-homogeneity"><span>16.3 A fourth identifying condition: homogeneity</span></a></h4><p><strong>Subchapter Content</strong></p><ul><li><strong>Homogeneity conditions (iv)</strong>: <ol><li>Constant treatment effect across individuals (implausible).</li><li>Equal average effect across (Z) in treated/untreated.</li><li>No additive effect modification by unmeasured (U).</li><li>Constant (Z)-(A) association across (U).</li></ol></li><li><strong>General condition</strong>:<br> [<br> \\text{Cov}\\left[E[Y^{a=1} - Y^{a=0}|U], E[A|Z=1,U] - E[A|Z=0,U]\\right] = 0.<br> ]</li><li><strong>Challenges</strong>: Homogeneity is often implausible (e.g., smoking cessation effect varies with unmeasured smoking intensity).</li></ul><p><strong>Technical Point (Technical Point 16.5)</strong></p><ul><li><strong>Proof</strong>: IV estimand equals (E[Y^{a=1} - Y^{a=0}]) under general homogeneity.</li></ul><hr><h4 id="_16-4-an-alternative-fourth-condition-monotonicity" tabindex="-1"><a class="header-anchor" href="#_16-4-an-alternative-fourth-condition-monotonicity"><span>16.4 An alternative fourth condition: monotonicity</span></a></h4><p><strong>Subchapter Content</strong></p><ul><li><strong>Compliance types</strong>: Always-takers, never-takers, compliers, defiers.</li><li><strong>Monotonicity (iv)</strong>: No defiers ((A^{z=1} \\geq A^{z=0})).</li><li><strong>IV estimand under monotonicity</strong>:<br> [<br> E[Y^{a=1} - Y^{a=0} | \\text{compliers}].<br> ]</li><li><strong>Criticisms</strong>: <ul><li>Compliers are unobservable and instrument-dependent.</li><li>Monotonicity may not hold in observational studies (e.g., physician preference instruments).</li><li>Interpretation unclear for surrogate instruments.</li></ul></li></ul><p><strong>Technical Points (Technical Point 16.6, 16.7)</strong></p><ul><li><strong>Structural mean models with covariates</strong>: Adjust for pre-instrument covariates (V).</li><li><strong>Proof</strong>: IV estimand = complier average causal effect (CACE) under monotonicity.</li></ul><hr><h4 id="_16-5-the-three-instrumental-conditions-revisited" tabindex="-1"><a class="header-anchor" href="#_16-5-the-three-instrumental-conditions-revisited"><span>16.5 The three instrumental conditions revisited</span></a></h4><p><strong>Subchapter Content</strong></p><ul><li><strong>Weak instruments (Fine Point 16.2)</strong>: <ul><li><em>Substantive</em>: Small (Z)-(A) association.</li><li><em>Statistical</em>: First-stage F-statistic &lt; 10.</li><li><strong>Problems</strong>: <ol><li>Wide confidence intervals.</li><li>Amplifies bias from violations of (ii)/(iii).</li><li>Finite-sample bias even with valid instruments.</li></ol></li></ul></li><li><strong>Violations of conditions</strong>: <ul><li>(ii) Direct effect of (Z) on (Y) (e.g., from coarsening treatment).</li><li>(iii) Confounding for (Z)-(Y) effect (Figure 16.10).</li></ul></li><li><strong>Mitigation</strong>: Adjust for measured covariates (V), but balance checks may be misleading.</li></ul><hr><h4 id="_16-6-instrumental-variable-estimation-versus-other-methods" tabindex="-1"><a class="header-anchor" href="#_16-6-instrumental-variable-estimation-versus-other-methods"><span>16.6 Instrumental variable estimation versus other methods</span></a></h4><p><strong>Subchapter Content</strong></p><ul><li><strong>Key differences from IP weighting/standardization</strong>: <ol><li>Replaces conditional exchangeability with IV assumptions.</li><li>Minor violations can cause large biases.</li><li>Best suited for point interventions with strong instruments.</li></ol></li><li><strong>Regression discontinuity (Fine Point 16.3)</strong>: Estimates causal effects near a cutoff (e.g., age 65 for treatment eligibility) under continuity assumptions.</li><li><strong>Triangulation</strong>: Combine IV with other methods for robustness.</li></ul><hr><p><strong>Figures Summary</strong></p><ul><li><strong>Figure 16.1</strong>: Causal instrument in a randomized trial.</li><li><strong>Figures 16.2–16.3</strong>: Surrogate instruments.</li><li><strong>Figures 16.4–16.7</strong>: Compliance types (always-takers, compliers, etc.).</li><li><strong>Figures 16.8–16.10</strong>: Violations of IV conditions (direct effects, confounding).</li></ul><p><strong>Key Limitations</strong></p><ul><li>Conditions (ii)/(iii) untestable; homogeneity/monotonicity often implausible.</li><li>Weak instruments amplify bias.</li><li>CACE may lack practical relevance.</li></ul>',40))])}const f=o(d,[["render",m]]),b=JSON.parse(`{"path":"/posts/Causal%20inference/What-if%20book%20reading%20notes/response_md/DeepSeek-R1-0528-2nd/Chapter_16.html","title":"Chapter_16","lang":"en-US","frontmatter":{"title":"Chapter_16","category":"Causal inference","tags":["DeepSeek-R1-0528-2nd","response_md"],"description":"### Chapter 16: INSTRUMENTAL VARIABLE ESTIMATION **Introduction** - Causal inference methods previously discussed require measuring all confounders, but residual bias persists i...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Chapter_16\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-09-17T03:19:05.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Aaron L\\",\\"url\\":\\"https://aaronlzm.github.io\\",\\"email\\":\\"lzm_aaron@outlook.com\\"}]}"],["meta",{"property":"og:url","content":"https://aaronlzm.github.io/posts/Causal%20inference/What-if%20book%20reading%20notes/response_md/DeepSeek-R1-0528-2nd/Chapter_16.html"}],["meta",{"property":"og:site_name","content":"Aaron's Blog"}],["meta",{"property":"og:title","content":"Chapter_16"}],["meta",{"property":"og:description","content":"### Chapter 16: INSTRUMENTAL VARIABLE ESTIMATION **Introduction** - Causal inference methods previously discussed require measuring all confounders, but residual bias persists i..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-09-17T03:19:05.000Z"}],["meta",{"property":"article:tag","content":"response_md"}],["meta",{"property":"article:tag","content":"DeepSeek-R1-0528-2nd"}],["meta",{"property":"article:modified_time","content":"2025-09-17T03:19:05.000Z"}]]},"git":{"createdTime":1758079145000,"updatedTime":1758079145000,"contributors":[{"name":"lizhimou","username":"lizhimou","email":"lizhimou@bytedance.com","commits":1,"url":"https://github.com/lizhimou"}]},"readingTime":{"minutes":3.67,"words":1101},"filePathRelative":"posts/Causal inference/What-if book reading notes/response_md/DeepSeek-R1-0528-2nd/Chapter_16.md","excerpt":"\\n### Chapter 16: INSTRUMENTAL VARIABLE ESTIMATION  \\n**Introduction**  \\n- Causal inference methods previously discussed require measuring all confounders, but residual bias persists if unmeasured confounders exist.  \\n- Instrumental variable (IV) estimation offers an alternative approach under different assumptions, avoiding the need to measure all confounders.  \\n","autoDesc":true}`);export{f as comp,b as data};
