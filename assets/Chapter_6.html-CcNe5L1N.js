import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,a as r,f as s,w as l,r as c,b as d,g as t,d as e}from"./app-p5c8ryjK.js";const u={};function g(p,i){const a=c("think");return d(),o("div",null,[r(a,null,{default:l(()=>[...i[0]||(i[0]=[t(' We are summarizing Chapter 6 of the provided PDF. The chapter is titled "GRAPHICAL REPRESENTATION OF CAUSAL EFFECTS". We will follow the structure of the chapter, which includes several sections and technical points. Since the chapter is long, we break it down by the sections as they appear in the text. ',-1),e("p",null,[t("The chapter starts with an introduction to causal diagrams and then moves to specific topics:"),e("br"),t(" 6.1 Causal diagrams"),e("br"),t(" 6.2 Causal diagrams and marginal independence"),e("br"),t(" 6.3 Causal diagrams and conditional independence"),e("br"),t(" 6.4 Positivity and consistency in causal diagrams"),e("br"),t(" 6.5 A structural classification of bias"),e("br"),t(" 6.6 The structure of effect modification")],-1),e("p",null,"Additionally, there are Technical Points (6.1, 6.2, 6.3) and Fine Points (6.1, 6.2, 6.3) that we need to incorporate.",-1),e("p",null,"We note that the chapter includes several figures. Since we cannot see the images, we will rely on the text descriptions and context to summarize the information about the figures.",-1),e("p",null,"We will structure the summary by the sections and subsections, and for each, we will extract:",-1),e("ul",null,[e("li",null,"Technical Points: core theories, definitions, and formulas"),e("li",null,"Details: explanations, examples, and key insights")],-1),e("p",null,"We must use Markdown, include LaTeX for formulas, and note when images are referenced but not described in detail.",-1),e("p",null,"Let's begin.",-1)])]),_:1}),i[1]||(i[1]=s(' ### Chapter 6: Graphical Representation of Causal Effects <h4 id="_6-1-causal-diagrams" tabindex="-1"><a class="header-anchor" href="#_6-1-causal-diagrams"><span>6.1 Causal Diagrams</span></a></h4><p>Causal diagrams (directed acyclic graphs, DAGs) visually encode qualitative knowledge about causal structures. Key properties:</p><ul><li><strong>Nodes</strong>: Represent variables (e.g., (L): disease severity, (A): treatment, (Y): outcome).</li><li><strong>Edges (arrows)</strong>: Indicate direct causal effects (e.g., (L \\rightarrow A) implies (L) affects (A)).</li><li><strong>Acyclicity</strong>: No feedback loops (variables cannot cause themselves).</li><li><strong>Temporal order</strong>: Conventionally flows left to right (e.g., (L) precedes (A), which precedes (Y)).</li><li><strong>Assumptions</strong>: <ul><li>Absence of an arrow (V_j \\rightarrow V_m) implies no direct causal effect of (V_j) on (V_m).</li><li>All common causes of any variables on the graph are included (even if unmeasured).</li></ul></li></ul><p><strong>Technical Point 6.1: Causal DAGs</strong></p><ul><li>A causal DAG (G) has vertices (V = (V_1, \\dots, V_M)) with directed edges and no cycles.</li><li><strong>Markov factorization</strong>: Density (f(v)) satisfies:<br> [<br> f(v) = \\prod_{j=1}^{M} f(v_j | \\text{pa}_j)<br> ]<br> where (\\text{pa}_j) are parents of (V_j).</li><li><strong>Causal Markov assumption</strong>: Conditional on its parents, (V_j) is independent of non-descendants.</li></ul><hr><h4 id="_6-2-causal-diagrams-and-marginal-independence" tabindex="-1"><a class="header-anchor" href="#_6-2-causal-diagrams-and-marginal-independence"><span>6.2 Causal Diagrams and Marginal Independence</span></a></h4><p>Association between variables arises from:</p><ol><li><strong>Causal paths</strong> (e.g., (A \\rightarrow Y) in Figure 6.2).</li><li><strong>Common causes</strong> (e.g., (L) in (A \\leftarrow L \\rightarrow Y), Figure 6.3).</li><li><strong>Colliders</strong> (common effects) block association unless conditioned on (e.g., (A \\rightarrow L \\leftarrow Y) in Figure 6.4 implies (A \\perp!!!\\perp Y) marginally).</li></ol><p><strong>Key Insight</strong>:</p><ul><li>Association flows through open paths. Colliders (e.g., (L) in (A \\rightarrow L \\leftarrow Y)) block association when not conditioned on.</li></ul><p><strong>Technical Point 6.2: Counterfactual Models</strong></p><ul><li>Nonparametric structural equation models (NPSEMs) define counterfactuals (e.g., (V_m^{r}) when (R) is set to (r)).</li><li>Models (e.g., FCISTG, FFRCISTG) link DAGs to counterfactual independencies.</li></ul><p><strong>Technical Point 6.3: Faithfulness and Independencies</strong></p><ul><li><strong>Faithfulness</strong>: Statistical independence implies d-separation (rare violations occur, e.g., perfect effect cancellation).</li><li><strong>NPSEM-IE vs. FFRCISTG</strong>: Differ in independence assumptions (e.g., NPSEM-IE requires independent errors).</li></ul><hr><h4 id="_6-3-causal-diagrams-and-conditional-independence" tabindex="-1"><a class="header-anchor" href="#_6-3-causal-diagrams-and-conditional-independence"><span>6.3 Causal Diagrams and Conditional Independence</span></a></h4><p>Conditioning affects association:</p><ul><li><strong>Blocking non-colliders</strong>: Conditioning on mediators (e.g., (B) in (A \\rightarrow B \\rightarrow Y), Figure 6.5) or common causes (e.g., (L) in (A \\leftarrow L \\rightarrow Y), Figure 6.6) removes association:<br> [<br> A \\perp!!!\\perp Y | B, \\quad A \\perp!!!\\perp Y | L.<br> ]</li><li><strong>Opening colliders</strong>: Conditioning on colliders (e.g., (L) in (A \\rightarrow L \\leftarrow Y), Figure 6.7) or their descendants (e.g., (C) in Figure 6.8) induces association.</li></ul><p><strong>Fine Point 6.1: d-Separation Rules</strong><br> A path is blocked if:</p><ol><li>It contains a non-collider conditioned on.</li><li>It contains an unconditioned collider with no conditioned descendants.<br><em>(Example: In Figure 6.1, (L \\rightarrow A \\rightarrow Y) is open; (A \\rightarrow Y \\leftarrow L) is blocked by collider (Y).)</em></li></ol><hr><h4 id="_6-4-positivity-and-consistency-in-causal-diagrams" tabindex="-1"><a class="header-anchor" href="#_6-4-positivity-and-consistency-in-causal-diagrams"><span>6.4 Positivity and Consistency in Causal Diagrams</span></a></h4><ul><li><strong>Positivity</strong>: Implicit in DAGs unless treatment is deterministic (e.g., bold (L \\rightarrow A) arrow).</li><li><strong>Consistency</strong>: Arrows from treatment nodes ((A)) must correspond to well-defined interventions.</li><li><strong>Limitation</strong>: DAGs cannot fully encode violations of positivity or ill-defined treatments (e.g., &quot;weight loss&quot; in Figure 6.10 has ambiguous interventions).</li></ul><hr><h4 id="_6-5-a-structural-classification-of-bias" tabindex="-1"><a class="header-anchor" href="#_6-5-a-structural-classification-of-bias"><span>6.5 A Structural Classification of Bias</span></a></h4><p><strong>Systematic bias</strong> arises when association ≠ causation due to:</p><ol><li><strong>Confounding</strong>: Common causes of treatment and outcome (e.g., (L) in Figure 6.1).</li><li><strong>Selection bias</strong>: Conditioning on common effects (e.g., (L) in Figure 6.7).</li><li><strong>Measurement bias</strong>: Addressed in Chapter 9.</li></ol><ul><li><strong>Bias under the null</strong>: Occurs when treatment has no effect but association exists (e.g., Table 3.1).</li></ul><p><strong>Fine Point 6.3: Causal Discovery</strong></p><ul><li>Learning DAG structure from data requires faithfulness and is often indeterminate (e.g., association between (B) and (C) could reflect (B \\rightarrow C), (C \\rightarrow B), or unmeasured common causes).</li></ul><hr><h4 id="_6-6-the-structure-of-effect-modification" tabindex="-1"><a class="header-anchor" href="#_6-6-the-structure-of-effect-modification"><span>6.6 The Structure of Effect Modification</span></a></h4><ul><li><strong>Causal effect modifiers</strong>: Directly affect outcome (e.g., quality of care (V) in Figure 6.12).</li><li><strong>Surrogate effect modifiers</strong>: Associated with causal modifiers but not causal (e.g., cost (S) in Figure 6.14).</li><li><strong>DAG limitations</strong>: Cannot distinguish effect modification types (e.g., qualitative vs. quantitative).</li></ul><p><strong>Key Insight</strong>:</p><ul><li>Surrogate modifiers arise from associations via common causes (e.g., (U) in Figure 6.15), conditioning (e.g., (S=0) in Figure 6.16), or mediation.</li></ul><hr><h3 id="summary-of-key-concepts" tabindex="-1"><a class="header-anchor" href="#summary-of-key-concepts"><span>Summary of Key Concepts</span></a></h3><table><thead><tr><th><strong>Concept</strong></th><th><strong>Definition</strong></th><th><strong>Example</strong></th></tr></thead><tbody><tr><td><strong>Causal DAG</strong></td><td>Graph encoding causal assumptions; no cycles, all common causes included.</td><td>Figure 6.1</td></tr><tr><td><strong>d-Separation</strong></td><td>Rules to determine conditional independence from DAG structure.</td><td>Fine Point 6.1</td></tr><tr><td><strong>Collider</strong></td><td>Common effect blocking association unless conditioned on.</td><td>(A \\rightarrow L \\leftarrow Y)</td></tr><tr><td><strong>Confounding Bias</strong></td><td>Due to common causes of treatment and outcome.</td><td>(L) in Figure 6.3</td></tr><tr><td><strong>Selection Bias</strong></td><td>Induced by conditioning on common effects.</td><td>Conditioning on (L) in Figure 6.7</td></tr><tr><td><strong>Effect Modification</strong></td><td>Heterogeneity in causal effects across subgroups.</td><td>(V) (quality of care in Figure 6.12)</td></tr></tbody></table><p><em>Note: Figures referenced (e.g., 6.1–6.16) are integral to examples but not fully describable from text alone.</em></p>',41))])}const f=n(u,[["render",g]]),b=JSON.parse(`{"path":"/posts/Causal%20inference/What-if%20book%20reading%20notes/response_md/DeepSeek-R1-0528-2nd/Chapter_6.html","title":"Chapter_6","lang":"en-US","frontmatter":{"title":"Chapter_6","category":"Causal inference","tags":["DeepSeek-R1-0528-2nd","response_md"],"description":"### Chapter 6: Graphical Representation of Causal Effects 6.1 Causal Diagrams Causal diagrams (directed acyclic graphs, DAGs) visually encode qualitative knowledge about causal ...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Chapter_6\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-09-17T03:19:05.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Aaron L\\",\\"url\\":\\"https://aaronlzm.github.io\\",\\"email\\":\\"lzm_aaron@outlook.com\\"}]}"],["meta",{"property":"og:url","content":"https://aaronlzm.github.io/posts/Causal%20inference/What-if%20book%20reading%20notes/response_md/DeepSeek-R1-0528-2nd/Chapter_6.html"}],["meta",{"property":"og:site_name","content":"Aaron's Blog"}],["meta",{"property":"og:title","content":"Chapter_6"}],["meta",{"property":"og:description","content":"### Chapter 6: Graphical Representation of Causal Effects 6.1 Causal Diagrams Causal diagrams (directed acyclic graphs, DAGs) visually encode qualitative knowledge about causal ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-09-17T03:19:05.000Z"}],["meta",{"property":"article:tag","content":"response_md"}],["meta",{"property":"article:tag","content":"DeepSeek-R1-0528-2nd"}],["meta",{"property":"article:modified_time","content":"2025-09-17T03:19:05.000Z"}]]},"git":{"createdTime":1758079145000,"updatedTime":1758079145000,"contributors":[{"name":"lizhimou","username":"lizhimou","email":"lizhimou@bytedance.com","commits":1,"url":"https://github.com/lizhimou"}]},"readingTime":{"minutes":3.32,"words":996},"filePathRelative":"posts/Causal inference/What-if book reading notes/response_md/DeepSeek-R1-0528-2nd/Chapter_6.md","excerpt":"\\n### Chapter 6: Graphical Representation of Causal Effects\\n<h4>6.1 Causal Diagrams</h4>\\n<p>Causal diagrams (directed acyclic graphs, DAGs) visually encode qualitative knowledge about causal structures. Key properties:</p>","autoDesc":true}`);export{f as comp,b as data};
