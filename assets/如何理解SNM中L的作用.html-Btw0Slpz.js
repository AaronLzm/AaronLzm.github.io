import{_ as l}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as t,d as s,f as n,b as i}from"./app-BlKdknS5.js";const e={};function m(p,a){return i(),t("div",null,[...a[0]||(a[0]=[s("p",null,"在结构嵌套模型（structural nested models, SNMs）中，您给出的方程：",-1),s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"E"),s("mo",{stretchy:"false"},"["),s("msup",null,[s("mi",null,"Y"),s("mi",null,"a")]),s("mo",null,"−"),s("msup",null,[s("mi",null,"Y"),s("mrow",null,[s("mi",null,"a"),s("mo",null,"="),s("mn",null,"0")])]),s("mo",null,"∣"),s("mi",null,"A"),s("mo",null,"="),s("mi",null,"a"),s("mo",{separator:"true"},","),s("mi",null,"L"),s("mo",{stretchy:"false"},"]"),s("mo",null,"="),s("msub",null,[s("mi",null,"β"),s("mn",null,"1")]),s("mi",null,"a"),s("mo",null,"+"),s("mi",null,[s("msub",null,[s("mi",{mathvariant:"bold-italic"},"β"),s("mn",{mathvariant:"bold"},"2")])]),s("mi",null,"a"),s("mi",null,"L")]),s("annotation",{encoding:"application/x-tex"},"E[Y^a - Y^{a=0} \\mid A=a, L] = \\beta_1 a + \\boldsymbol{\\beta_2} a L ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E"),s("span",{class:"mopen"},"["),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"Y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7144em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"a")])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1141em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"Y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"a"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"0")])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"∣"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal"},"A"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mclose"},"]"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05278em"}},"β"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0528em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord boldsymbol",style:{"margin-right":"0.03403em"}},"β"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.034em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathbf mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])]),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal"},"L")])])])])],-1),n('<p>描述了条件平均处理效应（CATE），其中：</p><ul><li>(Y^a) 是潜在结果（如果接受治疗 (A = a)），</li><li>(Y^{a=0}) 是潜在结果（如果未接受治疗，即 (A = 0)），</li><li>(A) 是治疗变量（通常为二元，如 (a = 0) 或 (a = 1)），</li><li>(L) 是协变量向量（可能包括混杂因子或效果修饰因子），</li><li>(\\beta_1) 和 (\\boldsymbol{\\beta_2}) 是待估计参数。</li></ul><p>这个模型假设处理效应（即 (Y^a - Y^{a=0})) 依赖于治疗 (A) 和协变量 (L)。具体来说：</p><ul><li>当 (a = 1) 时，CATE 为 $$\\beta_1 + \\boldsymbol{\\beta_2} L$$，</li><li>当 (a = 0) 时，CATE 为 0（因为方程右边为 0）。</li></ul><p>您的核心问题是“如何确认这里的 (L)”，即如何确定或选择协变量 (L) 以确保模型正确。这涉及两个层面：</p><ol><li><strong>选择 (L)</strong>：决定哪些变量应包含在 (L) 中。</li><li><strong>确认 (L) 的充分性</strong>：验证 (L) 是否已包含所有必要的混杂因子和效果修饰因子，以避免偏倚。</li></ol><p>以下我将逐步解释如何确认 (L)，基于结构嵌套模型的原理和标准实践（如 g-estimation）。结构嵌套模型依赖于无混淆假设（no unmeasured confounding），而 (L) 的选择直接关系到该假设是否成立。</p><hr><h3 id="_1-理解-l-的作用" tabindex="-1"><a class="header-anchor" href="#_1-理解-l-的作用"><span>1. <strong>理解 (L) 的作用</strong></span></a></h3><p>在您的模型中，(L) 有两个潜在角色：</p><ul><li><strong>混杂因子（Confounder）</strong>：影响治疗分配 (A) 和结果 (Y) 的变量。如果遗漏重要混杂因子，因果效应估计将有偏。</li><li><strong>效果修饰因子（Effect Modifier）</strong>：影响治疗效应大小（即 (\\boldsymbol{\\beta_2} a L) 项表示 (L) 修饰了处理效应）。模型显式假设 (L) 是效果修饰因子（因为与 (a) 有交互）。</li></ul><p>因此，确认 (L) 的目标是确保：</p><ul><li>(L) 包含所有先验的混杂因子（以消除混杂偏倚）。</li><li>(L) 包含所有重要的效果修饰因子（以正确建模效应异质性）。</li><li>(L) 的指定（如线性形式）正确，无遗漏变量或错误函数形式。</li></ul><hr><h3 id="_2-如何选择-l-基于先验知识" tabindex="-1"><a class="header-anchor" href="#_2-如何选择-l-基于先验知识"><span>2. <strong>如何选择 (L)（基于先验知识）</strong></span></a></h3><p>选择 (L) 主要依赖领域知识和因果图，而非纯数据驱动。因为因果推断中，混杂因子的识别本质上是基于假设。</p><h4 id="步骤" tabindex="-1"><a class="header-anchor" href="#步骤"><span>步骤：</span></a></h4><ul><li><strong>构建因果图（DAG）</strong>： <ul><li>绘制一个有向无环图（DAG），表示变量间的因果关系。</li><li>识别所有共同影响 (A) 和 (Y) 的变量（即混杂因子）。这些必须包含在 (L) 中。</li><li>例如，如果研究药物效果（(A)）和健康结局（(Y)），(L) 可能包括年龄、性别、基线健康状态等。</li></ul></li><li><strong>包含效果修饰因子</strong>： <ul><li>如果某些变量（如基因型或环境因素）可能改变治疗效果，也应包含在 (L) 中（因为它们出现在交互项 (\\boldsymbol{\\beta_2} a L) 中）。</li></ul></li><li><strong>避免无关变量</strong>： <ul><li>不要包括 (A) 的后件（如治疗后的变量），因为这会引入偏倚（如 M-偏差）。</li><li>避免工具变量（只影响 (A) 不影响 (Y)），因为它们可能增加方差但不减少偏倚。</li></ul></li><li><strong>示例</strong>： <ul><li>如果 DAG 显示变量集 (C = {L_1, L_2}) 阻塞了 (A) 到 (Y) 的所有后门路径，则 (L = {L_1, L_2})。</li><li>工具如 DAGitty（<a href="http://dagitty.net" target="_blank" rel="noopener noreferrer">dagitty.net</a>) 可帮助可视化。</li></ul></li></ul><h4 id="为什么先验知识优先" tabindex="-1"><a class="header-anchor" href="#为什么先验知识优先"><span>为什么先验知识优先？</span></a></h4><ul><li>数据无法完全测试无混淆假设（因为潜在结果不可观测）。</li><li>错误选择 (L)（如遗漏混杂因子）会导致参数估计偏倚。</li></ul><hr><h3 id="_3-如何确认-l-的充分性-基于数据和模型诊断" tabindex="-1"><a class="header-anchor" href="#_3-如何确认-l-的充分性-基于数据和模型诊断"><span>3. <strong>如何确认 (L) 的充分性（基于数据和模型诊断）</strong></span></a></h3><p>一旦初步选择 (L)，您需要使用数据和模型诊断来验证其充分性。结构嵌套模型通常通过 <strong>g-estimation</strong> 估计参数，这提供了诊断机会。以下是确认 (L) 的步骤：</p><h4 id="步骤-1-使用-g-estimation-估计参数" tabindex="-1"><a class="header-anchor" href="#步骤-1-使用-g-estimation-估计参数"><span>步骤 1: <strong>使用 g-estimation 估计参数</strong></span></a></h4><p>g-estimation 的核心是：在正确参数下，去混杂的潜在结果与治疗分配 (A) 独立（条件于 (L)）。</p><ul><li><p><strong>定义去混杂的潜在结果</strong>：<br> 基于您的模型，定义：<br> [<br> H(\\beta) = Y - \\beta_1 A - \\boldsymbol{\\beta_2} A L<br> ]<br> 在正确参数 (\\beta = (\\beta_1, \\boldsymbol{\\beta_2})) 下，(H(\\beta)) 估计了 (Y^{a=0})（未接受治疗的潜在结果）。</p></li><li><p><strong>g-estimation 过程</strong>：</p><ol><li>指定一个辅助模型为 (A) 给定 (L)（如逻辑回归）：<br> [<br> \\text{logit}(P(A=1 \\mid L)) = \\alpha_0 + \\boldsymbol{\\alpha_1} L<br> ]<br> 这是倾向得分模型。</li><li>对候选参数 (\\psi = (\\psi_1, \\boldsymbol{\\psi_2}))，计算 (H(\\psi) = Y - \\psi_1 A - \\boldsymbol{\\psi_2} A L)。</li><li>测试条件独立性：在给定 (L) 下，(A) 应与 (H(\\psi)) 独立。这通过以下回归实现：<br> [<br> \\text{模型： } g(E[A \\mid L, H(\\psi)]) = \\gamma_0 + \\boldsymbol{\\gamma_1} L + \\gamma_2 H(\\psi)<br> ]<br> 其中 (g) 是链接函数（如 logit）。</li><li>寻找 (\\psi) 使得 (\\gamma_2 = 0)（即 (H(\\psi)) 的系数为 0）。这通过求解估计方程（如 GEE）或网格搜索完成。</li><li>估计的参数 (\\hat{\\beta}) 是使 (\\gamma_2) 最接近 0 的值。</li></ol></li></ul><h4 id="步骤-2-诊断-l-的充分性" tabindex="-1"><a class="header-anchor" href="#步骤-2-诊断-l-的充分性"><span>步骤 2: <strong>诊断 (L) 的充分性</strong></span></a></h4><p>g-estimation 提供了诊断工具来检查 (L) 是否充分：</p><ul><li><strong>测试倾向得分模型的充分性</strong>： <ul><li>如果 (L) 遗漏了重要混杂因子，倾向得分模型（(A) 给定 (L)）会错误指定。</li><li>诊断：检查倾向得分模型的拟合（如 Hosmer-Lemeshow 检验、残差图）。如果拟合差（如 p 值低），表明 (L) 可能遗漏变量。</li></ul></li><li><strong>检查条件独立性</strong>： <ul><li>在估计的 (\\hat{\\beta}) 下，计算 (H(\\hat{\\beta}))。</li><li>回归 (A) 对 (L) 和 (H(\\hat{\\beta}))，测试 (H(\\hat{\\beta})) 的系数是否接近 0（在 g-estimation 中，它被设为 0，但您可以检查置信区间或 p 值）。</li><li>如果系数显著非零（如 p &lt; 0.05），表明 (L) 不充分（可能遗漏混杂因子）。</li></ul></li><li><strong>添加额外变量测试</strong>： <ul><li>如果怀疑 (L) 遗漏变量 (Z)，重新运行 g-estimation 用扩展的 (L^* = L \\cup Z)。</li><li>比较参数估计： <ul><li>如果 (\\hat{\\beta}_1) 或 (\\hat{\\boldsymbol{\\beta}}_2) 显著变化（超出置信区间），表明 (L) 不充分，(Z) 可能是重要混杂因子。</li></ul></li><li>示例：添加 (Z) 到倾向得分模型，重新估计并测试变化。</li></ul></li><li><strong>测试效果修饰</strong>： <ul><li>您的模型假设 (L) 是效果修饰因子（通过 (\\boldsymbol{\\beta_2} a L) 项）。</li><li>诊断：测试 (\\boldsymbol{\\beta_2} = 0)（使用 Wald 检验或似然比检验）。 <ul><li>如果不拒绝 (\\boldsymbol{\\beta_2} = 0)，表明 (L) 可能不是强效果修饰因子，可从模型中移除（但需谨慎，基于先验知识）。</li></ul></li></ul></li><li><strong>函数形式诊断</strong>： <ul><li>模型假设线性交互（(\\boldsymbol{\\beta_2} a L)）。如果 (L) 与效应非线性相关，模型可能错误。</li><li>诊断：添加高阶项（如 (a L^2)）或样条，测试其显著性。如果显著，需扩展 (L) 的表示。</li></ul></li></ul><h4 id="步骤-3-敏感性和鲁棒性分析" tabindex="-1"><a class="header-anchor" href="#步骤-3-敏感性和鲁棒性分析"><span>步骤 3: <strong>敏感性和鲁棒性分析</strong></span></a></h4><ul><li><strong>敏感性分析</strong>： <ul><li>评估未测量混杂的影响。例如： <ul><li>假设存在未观测变量 (U)，量化其如何改变估计（如使用 Rosenbaum 界限或基于参数的敏感性分析）。</li><li>工具：R 包 <code>sensemakr</code> 或 <code>EValue</code>。</li></ul></li><li>如果估计对合理范围的 (U) 敏感，表明 (L) 可能不充分。</li></ul></li><li><strong>比较替代模型</strong>： <ul><li>拟合不同 (L) 集的模型（如 (L) 仅含混杂因子 vs. (L) 含额外变量）。</li><li>使用信息准则（如 AIC/BIC）或交叉验证比较拟合，但因果模型更重参数稳定性而非预测精度。</li></ul></li><li><strong>双重稳健方法</strong>： <ul><li>虽非直接用于 SNMs，但可结合倾向得分和结果模型（如逆概率加权）。如果双重稳健估计与 g-estimation 类似，增加 (L) 的可靠性。</li></ul></li></ul><hr><h3 id="_4-常见陷阱和建议" tabindex="-1"><a class="header-anchor" href="#_4-常见陷阱和建议"><span>4. <strong>常见陷阱和建议</strong></span></a></h3><ul><li><strong>陷阱</strong>： <ul><li>遗漏混杂因子：最大风险，导致偏倚。始终优先基于 DAG。</li><li>过度调整：包括中介变量（如 (A) 的后件）会引入偏倚。</li><li>忽略效果修饰：如果 (L) 是修饰因子但未包括在交互项，效应异质性被忽略。</li><li>线性假设：真实效应可能非线性，使用 EDA（探索性数据分析）检查 (L) 与 (Y) 的关系。</li></ul></li><li><strong>建议</strong>： <ul><li><strong>先验知识主导</strong>：与领域专家合作定义 (L)。</li><li><strong>探索性分析</strong>：运行初步回归（如 (Y) 对 (A, L, A \\times L)）看交互显著性。</li><li><strong>软件实现</strong>：使用 R（如 <code>gesttools</code> 包）或 Stata（<code>stgest</code>）进行 g-estimation。</li><li><strong>报告不确定性</strong>：始终报告置信区间和敏感性结果。</li></ul></li></ul><hr><h3 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h3><p>确认结构嵌套模型中的 (L) 是一个迭代过程：</p><ol><li><strong>选择 (L) 基于因果图/领域知识</strong>：确保包含所有先验混杂因子和效果修饰因子。</li><li><strong>通过 g-estimation 诊断</strong>：测试倾向得分模型、条件独立性、参数稳定性。</li><li><strong>敏感性和替代分析</strong>：评估未测量混杂和模型形式。</li></ol><p>如果 g-estimation 显示条件独立性成立（即 (H(\\hat{\\beta})) 与 (A) 独立给定 (L)），且敏感性分析稳健，则 (L) 可被视为充分。但记住：<strong>无混淆假设不可完全测试</strong>，因此先验知识始终是基础。</p>',39)])])}const c=l(e,[["render",m]]),g=JSON.parse(`{"path":"/posts/Causal%20inference/What-if%20book%20reading%20notes/Chapter%2014/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3SNM%E4%B8%ADL%E7%9A%84%E4%BD%9C%E7%94%A8.html","title":"如何理解SNM中L的作用","lang":"en-US","frontmatter":{"date":"2025-09-17T11:19:05.000Z","title":"如何理解SNM中L的作用","category":"Causal inference","tags":["Chapter 14","What-if book reading notes"],"description":"在结构嵌套模型（structural nested models, SNMs）中，您给出的方程： E[Ya−Ya=0∣A=a,L]=β1​a+β2​aL 描述了条件平均处理效应（CATE），其中： (Y^a) 是潜在结果（如果接受治疗 (A = a)）， (Y^{a=0}) 是潜在结果（如果未接受治疗，即 (A = 0)）， (A) 是治疗变量（通常为...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"如何理解SNM中L的作用\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-09-17T11:19:05.000Z\\",\\"dateModified\\":\\"2025-11-26T03:53:06.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Aaron L\\",\\"url\\":\\"https://aaronlzm.github.io\\",\\"email\\":\\"lzm_aaron@outlook.com\\"}]}"],["meta",{"property":"og:url","content":"https://aaronlzm.github.io/posts/Causal%20inference/What-if%20book%20reading%20notes/Chapter%2014/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3SNM%E4%B8%ADL%E7%9A%84%E4%BD%9C%E7%94%A8.html"}],["meta",{"property":"og:site_name","content":"Aaron's Blog"}],["meta",{"property":"og:title","content":"如何理解SNM中L的作用"}],["meta",{"property":"og:description","content":"在结构嵌套模型（structural nested models, SNMs）中，您给出的方程： E[Ya−Ya=0∣A=a,L]=β1​a+β2​aL 描述了条件平均处理效应（CATE），其中： (Y^a) 是潜在结果（如果接受治疗 (A = a)）， (Y^{a=0}) 是潜在结果（如果未接受治疗，即 (A = 0)）， (A) 是治疗变量（通常为..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-11-26T03:53:06.000Z"}],["meta",{"property":"article:tag","content":"What-if book reading notes"}],["meta",{"property":"article:tag","content":"Chapter 14"}],["meta",{"property":"article:published_time","content":"2025-09-17T11:19:05.000Z"}],["meta",{"property":"article:modified_time","content":"2025-11-26T03:53:06.000Z"}]]},"git":{"createdTime":1758079145000,"updatedTime":1764129186000,"contributors":[{"name":"lizhimou","username":"lizhimou","email":"lizhimou@bytedance.com","commits":2,"url":"https://github.com/lizhimou"}]},"readingTime":{"minutes":7.57,"words":2271},"filePathRelative":"posts/Causal inference/What-if book reading notes/Chapter 14/如何理解SNM中L的作用.md","excerpt":"<p>在结构嵌套模型（structural nested models, SNMs）中，您给出的方程：</p>\\n<p v-pre=\\"\\" class=\\"katex-block\\"><span class=\\"katex-display\\"><span class=\\"katex\\"><span class=\\"katex-mathml\\"><math xmlns=\\"http://www.w3.org/1998/Math/MathML\\" display=\\"block\\"><semantics><mrow><mi>E</mi><mo stretchy=\\"false\\">[</mo><msup><mi>Y</mi><mi>a</mi></msup><mo>−</mo><msup><mi>Y</mi><mrow><mi>a</mi><mo>=</mo><mn>0</mn></mrow></msup><mo>∣</mo><mi>A</mi><mo>=</mo><mi>a</mi><mo separator=\\"true\\">,</mo><mi>L</mi><mo stretchy=\\"false\\">]</mo><mo>=</mo><msub><mi>β</mi><mn>1</mn></msub><mi>a</mi><mo>+</mo><mi><msub><mi mathvariant=\\"bold-italic\\">β</mi><mn mathvariant=\\"bold\\">2</mn></msub></mi><mi>a</mi><mi>L</mi></mrow><annotation encoding=\\"application/x-tex\\">E[Y^a - Y^{a=0} \\\\mid A=a, L] = \\\\beta_1 a + \\\\boldsymbol{\\\\beta_2} a L\\n</annotation></semantics></math></span><span class=\\"katex-html\\" aria-hidden=\\"true\\"><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:1em;vertical-align:-0.25em;\\"></span><span class=\\"mord mathnormal\\" style=\\"margin-right:0.05764em;\\">E</span><span class=\\"mopen\\">[</span><span class=\\"mord\\"><span class=\\"mord mathnormal\\" style=\\"margin-right:0.22222em;\\">Y</span><span class=\\"msupsub\\"><span class=\\"vlist-t\\"><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.7144em;\\"><span style=\\"top:-3.113em;margin-right:0.05em;\\"><span class=\\"pstrut\\" style=\\"height:2.7em;\\"></span><span class=\\"sizing reset-size6 size3 mtight\\"><span class=\\"mord mathnormal mtight\\">a</span></span></span></span></span></span></span></span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span><span class=\\"mbin\\">−</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:1.1141em;vertical-align:-0.25em;\\"></span><span class=\\"mord\\"><span class=\\"mord mathnormal\\" style=\\"margin-right:0.22222em;\\">Y</span><span class=\\"msupsub\\"><span class=\\"vlist-t\\"><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.8641em;\\"><span style=\\"top:-3.113em;margin-right:0.05em;\\"><span class=\\"pstrut\\" style=\\"height:2.7em;\\"></span><span class=\\"sizing reset-size6 size3 mtight\\"><span class=\\"mord mtight\\"><span class=\\"mord mathnormal mtight\\">a</span><span class=\\"mrel mtight\\">=</span><span class=\\"mord mtight\\">0</span></span></span></span></span></span></span></span></span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span><span class=\\"mrel\\">∣</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.6833em;\\"></span><span class=\\"mord mathnormal\\">A</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span><span class=\\"mrel\\">=</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:1em;vertical-align:-0.25em;\\"></span><span class=\\"mord mathnormal\\">a</span><span class=\\"mpunct\\">,</span><span class=\\"mspace\\" style=\\"margin-right:0.1667em;\\"></span><span class=\\"mord mathnormal\\">L</span><span class=\\"mclose\\">]</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span><span class=\\"mrel\\">=</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.8889em;vertical-align:-0.1944em;\\"></span><span class=\\"mord\\"><span class=\\"mord mathnormal\\" style=\\"margin-right:0.05278em;\\">β</span><span class=\\"msupsub\\"><span class=\\"vlist-t vlist-t2\\"><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.3011em;\\"><span style=\\"top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;\\"><span class=\\"pstrut\\" style=\\"height:2.7em;\\"></span><span class=\\"sizing reset-size6 size3 mtight\\"><span class=\\"mord mtight\\">1</span></span></span></span><span class=\\"vlist-s\\">​</span></span><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.15em;\\"><span></span></span></span></span></span></span><span class=\\"mord mathnormal\\">a</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span><span class=\\"mbin\\">+</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.8889em;vertical-align:-0.1944em;\\"></span><span class=\\"mord\\"><span class=\\"mord\\"><span class=\\"mord\\"><span class=\\"mord boldsymbol\\" style=\\"margin-right:0.03403em;\\">β</span><span class=\\"msupsub\\"><span class=\\"vlist-t vlist-t2\\"><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.3011em;\\"><span style=\\"top:-2.55em;margin-left:-0.034em;margin-right:0.05em;\\"><span class=\\"pstrut\\" style=\\"height:2.7em;\\"></span><span class=\\"sizing reset-size6 size3 mtight\\"><span class=\\"mord mathbf mtight\\">2</span></span></span></span><span class=\\"vlist-s\\">​</span></span><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.15em;\\"><span></span></span></span></span></span></span></span></span><span class=\\"mord mathnormal\\">a</span><span class=\\"mord mathnormal\\">L</span></span></span></span></span></p>","autoDesc":true}`);export{c as comp,g as data};
