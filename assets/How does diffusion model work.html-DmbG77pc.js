import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,d as n,b as e}from"./app-BN8VANwn.js";const t={};function l(h,s){return e(),a("div",null,s[0]||(s[0]=[n(`<h5 id="user" tabindex="-1"><a class="header-anchor" href="#user"><span>user</span></a></h5><p>How does diffusion model work?</p><h5 id="assistant" tabindex="-1"><a class="header-anchor" href="#assistant"><span>assistant</span></a></h5><div class="language-md line-numbers-mode" data-highlighter="shiki" data-ext="md" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-md"><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">Diffusion models are a class of generative models that have gained popularity for their ability to produce high-quality samples across various domains, such as images, audio, and text. They work by modeling the process of gradually adding noise to data and then learning to reverse this process to generate new samples. Here&#39;s a breakdown of how diffusion models work:</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">### 1. </span><span style="--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit;">**Forward Process (Diffusion):**</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">The forward process involves gradually adding noise to the data over a series of time steps. This process can be described as a Markov chain where each step adds a small amount of Gaussian noise to the data. The goal is to transform the data into a simple distribution, typically Gaussian noise, over a fixed number of steps.</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit;"> **Mathematical Formulation:**</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Start with data </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\(</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> x_0 </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> At each time step </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\(</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> t </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, add noise to get </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\(</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> x_t </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> using:</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\[</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">x_t = \\sqrt{\\alpha_t} x_{t-1} + \\sqrt{1-\\alpha_t} \\epsilon</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Here, </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\(</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> \\alpha_t </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> is a variance schedule, and </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\(</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> \\epsilon </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> is Gaussian noise.</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">### 2. </span><span style="--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit;">**Reverse Process (Denoising):**</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">The reverse process aims to learn how to denoise the data, effectively reversing the diffusion process to generate new samples from noise.</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit;"> **Training Objective:**</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> The model learns to predict the noise </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\(</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> \\epsilon </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> that was added at each step, given the noisy data </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\(</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> x_t </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> and the time step </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\(</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> t </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> The objective is to minimize the difference between the predicted noise and the actual noise added during the forward process.</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit;"> **Mathematical Formulation:**</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> The model predicts </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\(</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> \\epsilon </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> using a neural network </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\(</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> \\epsilon_\\theta(x_t, t) </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> The loss function is typically the mean squared error between the predicted and true noise:</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\[</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">L(\\theta) = \\mathbb{E}_{t, x_0, \\epsilon} \\left[ \\|\\epsilon - \\epsilon_\\theta(x_t, t)\\|^2 \\right]</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\]</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">### 3. </span><span style="--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit;">**Sampling:**</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">To generate new samples, the model starts with pure Gaussian noise and iteratively applies the learned reverse process to denoise it, step by step, until it reaches a sample in the data space.</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit;"> **Iterative Denoising:**</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Start with </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\(</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> x_T \\sim \\mathcal{N}(0, I) </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> For each step </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\(</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> t </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> from </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\(</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> T </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> to 1, use the model to predict the noise and update </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\(</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> x_{t-1} </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> using:</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\[</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{1-\\alpha_t}{\\sqrt{1-\\bar{\\alpha}</span><span style="--shiki-light:#A626A4;--shiki-light-font-style:italic;--shiki-dark:#C678DD;--shiki-dark-font-style:italic;">_t}} \\epsilon_</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">\\theta(x_t, t) \\right) + \\sigma_t z</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Here, </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\(</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> \\bar{\\alpha}_t </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> is the cumulative product of </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\(</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> \\alpha </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> values, and </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\(</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> \\sigma_t </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> is a small noise term to ensure stability.</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">### Advantages:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit;"> **Flexibility:**</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Can model complex distributions and generate high-quality samples.</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit;"> **Stability:**</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> The gradual nature of the diffusion process helps in stabilizing training.</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">### Applications:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Image generation</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Text-to-image synthesis</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Audio synthesis</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E5C07B;">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Video generation</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">Diffusion models have shown impressive results in generating realistic and diverse samples, making them a powerful tool in the field of generative modeling.</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,4)]))}const d=i(t,[["render",l]]),r=JSON.parse(`{"path":"/posts/machine_learning/diffusers/How%20does%20diffusion%20model%20work.html","title":"How does diffusion model work","lang":"en-US","frontmatter":{"title":"How does diffusion model work","description":"user How does diffusion model work? assistant","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"How does diffusion model work\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-09-11T07:19:18.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Aaron L\\",\\"url\\":\\"https://aaronlzm.github.io\\",\\"email\\":\\"lzm_aaron@outlook.com\\"}]}"],["meta",{"property":"og:url","content":"https://aaronlzm.github.io/posts/machine_learning/diffusers/How%20does%20diffusion%20model%20work.html"}],["meta",{"property":"og:site_name","content":"Aaron's Blog"}],["meta",{"property":"og:title","content":"How does diffusion model work"}],["meta",{"property":"og:description","content":"user How does diffusion model work? assistant"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-09-11T07:19:18.000Z"}],["meta",{"property":"article:modified_time","content":"2025-09-11T07:19:18.000Z"}]]},"git":{"createdTime":1757508567000,"updatedTime":1757575158000,"contributors":[{"name":"lizhimou","username":"lizhimou","email":"lizhimou@bytedance.com","commits":2,"url":"https://github.com/lizhimou"}]},"readingTime":{"minutes":1.55,"words":464},"filePathRelative":"posts/machine_learning/diffusers/How does diffusion model work.md","excerpt":"<h5>user</h5>\\n<p>How does diffusion model work?</p>\\n<h5>assistant</h5>\\n<div class=\\"language-md line-numbers-mode\\" data-highlighter=\\"shiki\\" data-ext=\\"md\\" style=\\"--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34\\"><pre class=\\"shiki shiki-themes one-light one-dark-pro vp-code\\"><code class=\\"language-md\\"><span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">Diffusion models are a class of generative models that have gained popularity for their ability to produce high-quality samples across various domains, such as images, audio, and text. They work by modeling the process of gradually adding noise to data and then learning to reverse this process to generate new samples. Here's a breakdown of how diffusion models work:</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#E45649;--shiki-dark:#E06C75\\">### 1. </span><span style=\\"--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit\\">**Forward Process (Diffusion):**</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">The forward process involves gradually adding noise to the data over a series of time steps. This process can be described as a Markov chain where each step adds a small amount of Gaussian noise to the data. The goal is to transform the data into a simple distribution, typically Gaussian noise, over a fixed number of steps.</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit\\"> **Mathematical Formulation:**</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> Start with data </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\(</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> x_0 </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\)</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">.</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> At each time step </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\(</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> t </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\)</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">, add noise to get </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\(</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> x_t </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\)</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> using:</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\[</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">x_t = \\\\sqrt{\\\\alpha_t} x_{t-1} + \\\\sqrt{1-\\\\alpha_t} \\\\epsilon</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\]</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> Here, </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\(</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> \\\\alpha_t </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\)</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> is a variance schedule, and </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\(</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> \\\\epsilon </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\)</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> is Gaussian noise.</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#E45649;--shiki-dark:#E06C75\\">### 2. </span><span style=\\"--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit\\">**Reverse Process (Denoising):**</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">The reverse process aims to learn how to denoise the data, effectively reversing the diffusion process to generate new samples from noise.</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit\\"> **Training Objective:**</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> The model learns to predict the noise </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\(</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> \\\\epsilon </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\)</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> that was added at each step, given the noisy data </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\(</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> x_t </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\)</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> and the time step </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\(</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> t </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\)</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">.</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> The objective is to minimize the difference between the predicted noise and the actual noise added during the forward process.</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit\\"> **Mathematical Formulation:**</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> The model predicts </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\(</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> \\\\epsilon </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\)</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> using a neural network </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\(</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> \\\\epsilon_\\\\theta(x_t, t) </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\)</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">.</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> The loss function is typically the mean squared error between the predicted and true noise:</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\[</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">L(\\\\theta) = \\\\mathbb{E}_{t, x_0, \\\\epsilon} \\\\left[ \\\\|\\\\epsilon - \\\\epsilon_\\\\theta(x_t, t)\\\\|^2 \\\\right]</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\]</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#E45649;--shiki-dark:#E06C75\\">### 3. </span><span style=\\"--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit\\">**Sampling:**</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">To generate new samples, the model starts with pure Gaussian noise and iteratively applies the learned reverse process to denoise it, step by step, until it reaches a sample in the data space.</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit\\"> **Iterative Denoising:**</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> Start with </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\(</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> x_T \\\\sim \\\\mathcal{N}(0, I) </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\)</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">.</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> For each step </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\(</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> t </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\)</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> from </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\(</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> T </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\)</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> to 1, use the model to predict the noise and update </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\(</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> x_{t-1} </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\)</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> using:</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\[</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">x_{t-1} = \\\\frac{1}{\\\\sqrt{\\\\alpha_t}} \\\\left( x_t - \\\\frac{1-\\\\alpha_t}{\\\\sqrt{1-\\\\bar{\\\\alpha}</span><span style=\\"--shiki-light:#A626A4;--shiki-light-font-style:italic;--shiki-dark:#C678DD;--shiki-dark-font-style:italic\\">_t}} \\\\epsilon_</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">\\\\theta(x_t, t) \\\\right) + \\\\sigma_t z</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\]</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> Here, </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\(</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> \\\\bar{\\\\alpha}_t </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\)</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> is the cumulative product of </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\(</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> \\\\alpha </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\)</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> values, and </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\(</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> \\\\sigma_t </span><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">\\\\)</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> is a small noise term to ensure stability.</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#E45649;--shiki-dark:#E06C75\\">### Advantages:</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit\\"> **Flexibility:**</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> Can model complex distributions and generate high-quality samples.</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#986801;--shiki-light-font-weight:bold;--shiki-dark:#D19A66;--shiki-dark-font-weight:inherit\\"> **Stability:**</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> The gradual nature of the diffusion process helps in stabilizing training.</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#E45649;--shiki-dark:#E06C75\\">### Applications:</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> Image generation</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> Text-to-image synthesis</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> Audio synthesis</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#E5C07B\\">-</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> Video generation</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">Diffusion models have shown impressive results in generating realistic and diverse samples, making them a powerful tool in the field of generative modeling.</span></span></code></pre>\\n<div class=\\"line-numbers\\" aria-hidden=\\"true\\" style=\\"counter-reset:line-number 0\\"><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div></div></div>","autoDesc":true}`);export{d as comp,r as data};
